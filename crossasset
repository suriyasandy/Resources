import pandas as pd
from math import fabs

# -------------------------------
# 1. LOAD DATA
# -------------------------------

gfx = pd.read_csv("gfx_alerts.csv")
ird = pd.read_csv("ird_alerts.csv")

# -------------------------------
# 2. BASIC CLEANUP / PREP
# -------------------------------

# Standardize timestamps
gfx['time'] = pd.to_datetime(gfx['omrctradetradedatetime'], errors='coerce')
ird['time'] = pd.to_datetime(ird['omrctradetradedatetime'], errors='coerce')

# Extract FX base/quote from pair e.g. USD/JPY
gfx['fx_base']  = gfx['omrctradeInstrument'].str[:3]
gfx['fx_quote'] = gfx['omrctradeInstrument'].str[-3:]

# Standardize IRD currency fields
ird['ccy_notional'] = ird['notional_ccy']
ird['ccy_base']     = ird['base_ccy']
ird['ccy_pnl']      = ird['pnl_ccy']

# Numeric notional conversion
gfx['gfx_notional'] = pd.to_numeric(gfx['omrctradeNotionalreportingccy'], errors='coerce')
ird['ird_notional'] = pd.to_numeric(ird['omrctradeNotionalreportingccy'], errors='coerce')

# -------------------------------
# 3. BUILD SURROGATE JOIN KEY
# -------------------------------

gfx['link_key'] = (
    gfx['omrctradeLegalentity'].astype(str) + '_' +
    gfx['omrctradeBookname'].astype(str)
)

ird['link_key'] = (
    ird['omrctradeLegalentity'].astype(str) + '_' +
    ird['omrctradeBookname'].astype(str)
)

# -------------------------------
# 4. INITIAL INNER MERGE (NO CP JOIN)
# -------------------------------

cand = gfx.merge(
    ird, how='inner', on='link_key', suffixes=('_gfx','_ird')
)

# -------------------------------
# 5. CALCULATE LINK SCORE (SOFT RULES)
# -------------------------------

def calc_link_score(row):
    score = 0
    
    # 1. Currency overlap (must exist)
    fx_set = {row['fx_base_gfx'], row['fx_quote_gfx']}
    ird_set = {row['ccy_notional_ird'], row['ccy_base_ird'], row['ccy_pnl_ird']}
    if len(fx_set.intersection(ird_set)) == 0:
        return 0  # Reject
    score += 1  # Strong match

    # 2. Book/Legal Entity already matched by merge
    score += 1

    # 3. Notional similarity
    g = row['gfx_notional']
    i = row['ird_notional']
    if g > 0 and i > 0:
        ratio = fabs(g - i) / g
        if ratio <= 0.5:
            score += 1
        elif ratio <= 1.0:
            score += 0.5

    # 4. Time score (soft)
    if pd.notna(row['time_gfx']) and pd.notna(row['time_ird']):
        td = fabs((row['time_gfx'] - row['time_ird']).total_seconds()) / 60
        if td <= 30:
            score += 1
        elif td <= 24*60:
            score += 0.5
        elif td <= 48*60:
            score += 0.25

    return score

cand['link_score'] = cand.apply(calc_link_score, axis=1)

# -------------------------------
# 6. KEEP STRONG MATCHES
# -------------------------------

# Threshold for linked trades
linked_df = cand[cand['link_score'] >= 2.5].copy()

# -------------------------------
# 7. GET UNLINKED ALERTS
# -------------------------------

gfx_unlinked = gfx[~gfx['exceptionId'].isin(linked_df['exceptionId_gfx'])]
ird_unlinked = ird[~ird['exceptionId'].isin(linked_df['exceptionId_ird'])]

# -------------------------------
# 8. EXPORT RESULTS
# -------------------------------

linked_df.to_csv("linked_gfx_ird_alerts_scored.csv", index=False)
gfx_unlinked.to_csv("gfx_unlinked_alerts.csv", index=False)
ird_unlinked.to_csv("ird_unlinked_alerts.csv", index=False)

print("\n===== CROSS-ASSET LINKING COMPLETE =====")
print(f"Likely Linked Alerts:  {len(linked_df)}")
print(f"GFX Standalone Alerts: {len(gfx_unlinked)}")
print(f"IRD Standalone Alerts: {len(ird_unlinked)}")
print("Files written:")
print(" linked_gfx_ird_alerts_scored.csv")
print(" gfx_unlinked_alerts.csv")
print(" ird_unlinked_alerts.csv")
