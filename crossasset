import pandas as pd

# -------------------------------
# 1. LOAD DATA
# -------------------------------

gfx = pd.read_csv("gfx_alerts.csv")
ird = pd.read_csv("ird_alerts.csv")

# -------------------------------
# 2. BASIC CLEANUP / PREP
# -------------------------------

# Standardize timestamps
gfx['time'] = pd.to_datetime(gfx['omrctradetradedatetime'])
ird['time'] = pd.to_datetime(ird['omrctradetradedatetime'])

# Extract FX legs (Example instrument: EUR/USD, USD/JPY)
gfx['fx_base']  = gfx['omrctradeInstrument'].str[:3]
gfx['fx_quote'] = gfx['omrctradeInstrument'].str[-3:]

# Standardize IRD currencies
ird['ccy_notional'] = ird['notional_ccy']
ird['ccy_base']     = ird['base_ccy']
ird['ccy_pnl']      = ird['pnl_ccy']

# Ensure numeric notional comparison works
gfx['gfx_notional'] = pd.to_numeric(gfx['omrctradeNotionalreportingccy'], errors='coerce')
ird['ird_notional'] = pd.to_numeric(ird['omrctradeNotionalreportingccy'], errors='coerce')

# -------------------------------
# 3. BUILD SURROGATE JOIN KEY
#    (Legal Entity + Book name)
# -------------------------------

gfx['link_key'] = (
    gfx['omrctradeLegalentity'].astype(str) + '_' +
    gfx['omrctradeBookname'].astype(str)
)

ird['link_key'] = (
    ird['omrctradeLegalentity'].astype(str) + '_' +
    ird['omrctradeBookname'].astype(str)
)

# -------------------------------
# 4. INITIAL INNER MERGE
# -------------------------------

cand = gfx.merge(
    ird, how='inner', on='link_key', suffixes=('_gfx','_ird')
)

# -------------------------------
# 5. FILTER 1: TIME WINDOW
#    (Same trade idea: +/- 20 minutes)
# -------------------------------

cand = cand[
    abs(cand['time_gfx'] - cand['time_ird']) <= pd.Timedelta(minutes=20)
]

# -------------------------------
# 6. FILTER 2: CURRENCY OVERLAP
#    (ANY IRD CCY must appear in FX pair)
# -------------------------------

def ccymatch(row):
    fx_set = {row['fx_base_gfx'], row['fx_quote_gfx']}
    ird_set = {row['ccy_notional_ird'], row['ccy_base_ird'], row['ccy_pnl_ird']}
    return len(fx_set.intersection(ird_set)) > 0

cand['ccy_match'] = cand.apply(ccymatch, axis=1)
cand = cand[cand['ccy_match'] == True]

# -------------------------------
# 7. FILTER 3: NOTIONAL TOLERANCE
#    (Rough economic sizing check)
# -------------------------------

cand = cand[
    abs(cand['gfx_notional'] - cand['ird_notional'])
    <= 0.5 * cand['gfx_notional']
]

# -------------------------------
# 8. FINAL CONSOLIDATED OUTPUT
# -------------------------------

linked_cols = [
    'exceptionId_gfx','fx_base_gfx','fx_quote_gfx','gfx_notional','time_gfx',
    'exceptionId_ird','ccy_notional_ird','ird_notional','time_ird',
    'omrctradeLegalentity_gfx','omrctradeBookname_gfx'
]

linked_df = cand[linked_cols].reset_index(drop=True)

# -------------------------------
# 9. GET UNLINKED ALERTS
# -------------------------------

gfx_unlinked = gfx[~gfx['exceptionId'].isin(linked_df['exceptionId_gfx'])]
ird_unlinked = ird[~ird['exceptionId'].isin(linked_df['exceptionId_ird'])]

# -------------------------------
# 10. SAVE OUTPUT FILES
# -------------------------------

linked_df.to_csv("linked_gfx_ird_alerts.csv", index=False)
gfx_unlinked.to_csv("gfx_unlinked_alerts.csv", index=False)
ird_unlinked.to_csv("ird_unlinked_alerts.csv", index=False)

print("DONE!")
print(f"Linked Alerts Found: {len(linked_df)}")
print(f"GFX standalone alerts: {len(gfx_unlinked)}")
print(f"IRD standalone alerts: {len(ird_unlinked)}")
