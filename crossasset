import pandas as pd
from math import fabs

# ---------------------------------------
# 1. LOAD INPUT FILES
# ---------------------------------------

gfx = pd.read_csv("gfx_alerts.csv")
ird = pd.read_csv("ird_alerts.csv")

# ---------------------------------------
# 2. CLEANUP & BASIC NORMALIZATION
# ---------------------------------------

# Convert trade times (optional context only)
gfx['time'] = pd.to_datetime(gfx['omrctradetradedatetime'], errors='coerce')
ird['time'] = pd.to_datetime(ird['omrctradetradedatetime'], errors='coerce')

# Extract currencies from FX pair like USD/JPY
gfx['fx_base']  = gfx['omrctradeInstrument'].str[:3]
gfx['fx_quote'] = gfx['omrctradeInstrument'].str[-3:]

# Ensure IRD currency fields exist consistently
ird['ccy_notional'] = ird['notional_ccy']
ird['ccy_base']     = ird['base_ccy']
ird['ccy_pnl']      = ird['pnl_ccy']

# Convert notional numeric
gfx['gfx_notional'] = pd.to_numeric(gfx['omrctradeNotionalreportingccy'], errors='coerce')
ird['ird_notional'] = pd.to_numeric(ird['omrctradeNotionalreportingccy'], errors='coerce')

# ---------------------------------------
# 3. TENOR DERIVATION
# ---------------------------------------

### 3A. IRD TENOR
# Start date fallback = trade execution date
ird['start'] = pd.to_datetime(
    ird['tradeStartDate'].fillna(ird['time']),
    errors='coerce'
)
ird['end'] = pd.to_datetime(
    ird['maturity_date'].fillna(ird['terminationDate']),
    errors='coerce'
)

ird['tenor_days'] = (ird['end'] - ird['start']).dt.days

def tenor_bucket_ird(days):
    if pd.isna(days): return 'UNK'
    if days <= 7: return '1W'
    if days <= 30: return '1M'
    if days <= 90: return '3M'
    if days <= 180: return '6M'
    if days <= 365: return '12M'
    if days <= 3*365: return '3Y'
    if days <= 5*365: return '5Y'
    return '10Y+'

ird['tenor_bucket'] = ird['tenor_days'].apply(tenor_bucket_ird)

### 3B. GFX TENOR
# If tenor field exists
if 'omrctradeTenor' in gfx.columns:
    tenor_col = 'omrctradeTenor'
else:
    tenor_col = None

def map_gfx_tenor(x):
    if pd.isna(x):
        return 'UNK'
    x = str(x).upper().strip()
    if x in ['SPT','SP','SPOT','ON','TN']:  return '1W'
    if x.endswith('W'): return '1W'
    if x.endswith('M'): return x   # 1M,3M,6M keep as is
    if x.endswith('Y'): return x   # 1Y keep as is
    return 'UNK'

if tenor_col:
    gfx['tenor_bucket'] = gfx[tenor_col].apply(map_gfx_tenor)
else:
    # fallback from maturity date
    gfx['mat'] = pd.to_datetime(
        gfx['omrctradeMaturityDate'].fillna(gfx['omrctradeSettlDate']),
        errors='coerce'
    )
    gfx['start'] = gfx['time']
    gfx['tenor_days'] = (gfx['mat'] - gfx['start']).dt.days
    gfx['tenor_bucket'] = gfx['tenor_days'].apply(tenor_bucket_ird)

# ---------------------------------------
# 4. MERGE ON LEGAL ENTITY (STRONGEST CROSS-ASSET KEY)
# ---------------------------------------

gfx['link_key'] = gfx['omrctradeLegalentity'].astype(str)
ird['link_key'] = ird['omrctradeLegalentity'].astype(str)

cand = gfx.merge(ird, how='inner', on='link_key', suffixes=('_gfx','_ird'))

# ---------------------------------------
# 5. CALCULATE LINK SCORE
# ---------------------------------------

def calc_link_score(row):
    score = 0
    
    # 1. CURRENCY OVERLAP (binary must-have)
    fx_set = {row['fx_base_gfx'], row['fx_quote_gfx']}
    ird_set = {row['ccy_notional_ird'], row['ccy_base_ird'], row['ccy_pnl_ird']}
    if len(fx_set.intersection(ird_set)) == 0:
        return 0
    score += 1

    # 2. LEGAL ENTITY MATCH IN MERGE
    score += 1

    # 3. NOTIONAL PROPORTION
    g = row['gfx_notional']
    i = row['ird_notional']
    if g > 0 and i > 0:
        ratio = fabs(g - i) / g
        if ratio <= 0.5:
            score += 1
        elif ratio <= 1.0:
            score += 0.5

    # 4. TENOR BUCKET MATCH
    t_g = row['tenor_bucket_gfx']
    t_i = row['tenor_bucket_ird']
    if t_g == t_i and t_g != 'UNK':
        score += 1.25
    else:
        # allow small difference (e.g., 1M vs 3M for rolling hedges)
        buckets = ['1W','1M','3M','6M','12M','3Y','5Y','10Y+']
        try:
            diff = abs(buckets.index(t_g) - buckets.index(t_i))
            if diff == 1:
                score += 0.5
        except:
            pass

    return score

cand['link_score'] = cand.apply(calc_link_score, axis=1)

# ---------------------------------------
# 6. SELECT LIKELY LINKED TRADES
# ---------------------------------------

linked_df = cand[cand['link_score'] >= 2.5].copy()

# ---------------------------------------
# 7. FIND UNLINKED ALERTS
# ---------------------------------------

gfx_unlinked = gfx[~gfx['exceptionId'].isin(linked_df['exceptionId_gfx'])]
ird_unlinked = ird[~ird['exceptionId'].isin(linked_df['exceptionId_ird'])]

# ---------------------------------------
# 8. SAVE OUTPUT FILES
# ---------------------------------------

linked_df.to_csv("linked_gfx_ird_tenor_scored.csv", index=False)
gfx_unlinked.to_csv("gfx_unlinked_alerts.csv", index=False)
ird_unlinked.to_csv("ird_unlinked_alerts.csv", index=False)

print("\n===== TENOR-BASED LINKING COMPLETED SUCCESSFULLY =====")
print(f"Linked Alerts Identified : {len(linked_df)}")
print(f"GFX Standalone Alerts    : {len(gfx_unlinked)}")
print(f"IRD Standalone Alerts    : {len(ird_unlinked)}")
print("Output files created:")
print("  linked_gfx_ird_tenor_scored.csv")
print("  gfx_unlinked_alerts.csv")
print("  ird_unlinked_alerts.csv")
