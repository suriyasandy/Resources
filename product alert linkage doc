import pandas as pd
import numpy as np

# =========================================================
# ASSUMPTIONS
# =========================================================
# ird_df     -> IRD alerts / trades
# cb_df      -> Cash Bond alerts / trades
# curve_df   -> Daily curve data
#
# curve_df columns:
#   business_date
#   curve_name        (SOFR / SONIA / ESTER)
#   tenor             (<=2yr, 2-10yr, >10yr)
#   rate_value        (numeric)
# =========================================================


# =========================================================
# 1. DATE NORMALISATION
# =========================================================

ird_df['business_date'] = pd.to_datetime(ird_df['business_date'], errors='coerce')
ird_df['start_date'] = pd.to_datetime(ird_df['start_date'], errors='coerce')
ird_df['maturity_date'] = pd.to_datetime(ird_df['maturity_date'], errors='coerce')
ird_df['trade_datetime'] = pd.to_datetime(ird_df['trade_datetime'], errors='coerce')

cb_df['business_date'] = pd.to_datetime(cb_df['as_at_date'], errors='coerce')
cb_df['trade_datetime'] = pd.to_datetime(cb_df['trade_datetime'], errors='coerce')

curve_df['business_date'] = pd.to_datetime(curve_df['business_date'], errors='coerce')
curve_df['tenor'] = curve_df['tenor'].str.strip()


# =========================================================
# 2. IRD TENOR DERIVATION
# =========================================================

ird_df['tenor_years'] = np.where(
    (ird_df['start_date'].notna()) &
    (ird_df['maturity_date'].notna()) &
    (ird_df['maturity_date'] >= ird_df['start_date']),
    (ird_df['maturity_date'] - ird_df['start_date']).dt.days / 365,
    np.nan
)

def bucket_tenor(years):
    if pd.isna(years):
        return 'UNKNOWN'
    elif years <= 2:
        return '<=2yr'
    elif years <= 10:
        return '2-10yr'
    else:
        return '>10yr'

ird_df['tenor'] = ird_df['tenor_years'].apply(bucket_tenor)
ird_df['tenor_source'] = np.where(
    ird_df['tenor'] == 'UNKNOWN',
    'MISSING_DATES',
    'DATE_DERIVED'
)


# =========================================================
# 3. CASH BOND TENOR CLEANUP
# =========================================================

cb_df['tenor'] = (
    cb_df['tenor']
    .astype(str)
    .str.strip()
    .str.lower()
    .replace({
        '<=2yr': '<=2yr',
        '2-10yr': '2-10yr',
        '>10yr': '>10yr'
    })
)


# =========================================================
# 4. CANONICAL ALERT VIEWS
# =========================================================

ird_alerts = ird_df[[
    'execution_key',
    'business_date',
    'trade_datetime',
    'base_currency_cd',
    'tenor',
    'book',
    'legal_entity',
    'trader_id',
    'risk_curveid',
    'alert_description'
]].copy()

ird_alerts.rename(columns={
    'execution_key': 'alert_id',
    'base_currency_cd': 'currency',
    'risk_curveid': 'curve_source'
}, inplace=True)

ird_alerts['product_type'] = 'IRD'


cb_alerts = cb_df[[
    'trade_ref',
    'business_date',
    'trade_datetime',
    'currency',
    'tenor',
    'book',
    'legal_entity',
    'trader_id',
    'market_level_source',
    'alert_description'
]].copy()

cb_alerts.rename(columns={
    'trade_ref': 'alert_id',
    'market_level_source': 'curve_source'
}, inplace=True)

cb_alerts['product_type'] = 'CASHBOND'


# =========================================================
# 5. CB ↔ IRD LINK CANDIDATES (RATE RISK)
# =========================================================

link_candidates = cb_alerts.merge(
    ird_alerts,
    on=['business_date', 'currency', 'tenor'],
    how='inner',
    suffixes=('_cb', '_ird')
)


# =========================================================
# 6. SOFT CONFIRMATION SIGNALS
# =========================================================

link_candidates['same_book'] = (
    link_candidates['book_cb'] == link_candidates['book_ird']
)

link_candidates['same_trader'] = (
    link_candidates['trader_id_cb'] == link_candidates['trader_id_ird']
)

link_candidates['time_diff_minutes'] = (
    abs(link_candidates['trade_datetime_cb'] -
        link_candidates['trade_datetime_ird'])
    .dt.total_seconds() / 60
)


# =========================================================
# 7. LINK CONFIDENCE SCORE
# =========================================================

link_candidates['link_score'] = (
    1 +
    link_candidates['same_book'].astype(int) +
    link_candidates['same_trader'].astype(int) +
    (link_candidates['time_diff_minutes'] <= 1440).astype(int)
)

link_candidates['link_strength'] = np.where(
    link_candidates['link_score'] >= 3,
    'STRONG',
    'WEAK'
)


# =========================================================
# 8. CURVE RATE MOVEMENT (ΔRate)
# =========================================================

curve_df = curve_df.sort_values(
    ['curve_name', 'tenor', 'business_date']
)

curve_df['prev_rate'] = curve_df.groupby(
    ['curve_name', 'tenor']
)['rate_value'].shift(1)

curve_df['delta_rate_bps'] = (
    (curve_df['rate_value'] - curve_df['prev_rate']) * 100
)


# =========================================================
# 9. ATTACH RATE MOVEMENT TO LINKED PAIRS
# =========================================================

link_candidates['risk_curve'] = (
    link_candidates['curve_source_ird']
    .fillna(link_candidates['curve_source_cb'])
)

link_with_rate = link_candidates.merge(
    curve_df[['business_date', 'curve_name', 'tenor', 'delta_rate_bps']],
    left_on=['business_date', 'risk_curve', 'tenor'],
    right_on=['business_date', 'curve_name', 'tenor'],
    how='left'
)


# =========================================================
# 10. PnL ALERT FLAGS
# =========================================================

link_with_rate['cb_pnl_alert'] = (
    link_with_rate['alert_description_cb']
    .str.contains('PNL', case=False, na=False)
)

link_with_rate['ird_pnl_alert'] = (
    link_with_rate['alert_description_ird']
    .str.contains('PNL', case=False, na=False)
)


# =========================================================
# 11. RATE MOVE MATERIALITY
# =========================================================

RATE_MOVE_THRESHOLD = 2.0  # bps

link_with_rate['rate_move_flag'] = (
    link_with_rate['delta_rate_bps'].abs() >= RATE_MOVE_THRESHOLD
)


# =========================================================
# 12. EARLY RATE STRESS SIGNAL (PoC ONLY)
# =========================================================

link_with_rate['rate_stress_signal'] = np.where(
    (link_with_rate['ird_pnl_alert']) &
    (~link_with_rate['cb_pnl_alert']) &
    (link_with_rate['rate_move_flag']),
    'Y',
    'N'
)


# =========================================================
# 13. PoC METRICS / RESULTS
# =========================================================

coverage = (
    link_with_rate['alert_id_cb'].nunique() /
    cb_alerts['alert_id'].nunique()
)

print(f"\nCB alerts with IRD link candidates: {coverage:.2%}")

print("\nLink strength distribution:")
print(link_with_rate['link_strength'].value_counts())

print("\nIRD vs CB PnL hit rates (rate move days):")
rate_days = link_with_rate[link_with_rate['rate_move_flag']]
print("IRD Hit Rate:", rate_days['ird_pnl_alert'].mean())
print("CB  Hit Rate:", rate_days['cb_pnl_alert'].mean())

print("\nEarly rate stress signals:")
print(link_with_rate['rate_stress_signal'].value_counts())

link_with_rate.head()
