"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   PROFESSIONAL AUDIT SAMPLING TOOL v6.5 - ENHANCED WITH MUS & RISK WEIGHTING  â•‘
â•‘     Follows: AICPA AU-C 530, IIA Standards, ISA 530, COSO Framework           â•‘
â•‘   Advanced: MUS | Risk Weighting | Anomaly Detection | Statistical Analysis   â•‘
â•‘              Complete UI | Statistical Analysis | Audit Trail                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FILE: ProfessionalAuditSamplingTool_v650.py
VERSION: 6.5 - Enhanced with MUS & Statistical Risk Weighting
DATE: December 9, 2025
STATUS: âœ“ PRODUCTION READY - AUDIT GRADE

NEW FEATURES IN v6.5:
  âœ“ Monetary Unit Sampling (MUS) - for value-based testing
  âœ“ Statistical Risk Weighting - from exception frequency data
  âœ“ Composite Risk Scoring - multi-factor analysis
  âœ“ Advanced Anomaly Detection - IsolationForest + Statistical
  âœ“ Risk Weight Visualization - heat maps & distributions
  âœ“ Enhanced Exception Analysis - frequency & pattern detection
  âœ“ Comparative Sampling Analysis - multiple methods side-by-side
  âœ“ Statistical Weight Export - detailed risk documentation

SAMPLING METHODS:
  âœ“ Monetary Unit Sampling (MUS)
  âœ“ Stratified Risk-Based Sampling (Risk-Based)
  âœ“ Hybrid Sampling (Risk + Anomaly)
  âœ“ Attribute Sampling
  âœ“ Traditional Random Sampling

INSTALLATION:
  pip install pandas numpy scikit-learn matplotlib seaborn scipy openpyxl

RUN:
  python ProfessionalAuditSamplingTool_v650.py
"""

import tkinter as tk
from tkinter import ttk, messagebox, filedialog, scrolledtext
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from scipy import stats
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import math
import os
import traceback
from datetime import datetime
import warnings

warnings.filterwarnings('ignore')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENHANCED AUDIT SAMPLING ENGINE - WITH MUS & RISK WEIGHTING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EnhancedAuditEngine:
    """Enhanced audit sampling engine with MUS and statistical risk weighting"""
    
    def __init__(self):
        self.data = None
        self.strata_cols = []
        self.results = {}
        self.risk_assessment = {}
        self.risk_weights = {}
        self.entity_weights = {}
        self.regional_weights = {}
        self.results_dir = "AuditResults"
        self.create_dir()
    
    def create_dir(self):
        if not os.path.exists(self.results_dir):
            os.makedirs(self.results_dir)
    
    def sanitize_data(self, df):
        """Sanitize and validate data"""
        df = df.copy()
        
        for col in df.columns:
            try:
                numeric = pd.to_numeric(df[col], errors='coerce')
                if numeric.notna().sum() / len(df) >= 0.5:
                    df[col] = numeric
            except:
                pass
        
        return df
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STATISTICAL RISK WEIGHTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calculate_statistical_weights(self, df, category_col):
        """
        Calculate statistical weights based on exception frequency
        
        Weight = 0.1 + 0.9 * (Frequency - MinFreq) / (MaxFreq - MinFreq)
        
        Ensures: No zero weights, normalized 0.1-1.0 range, data-driven
        """
        
        try:
            # Calculate frequency distribution
            counts = df[category_col].value_counts()
            total_count = len(df)
            frequencies = counts / total_count
            
            # Normalize to [0.1, 1.0] range
            if len(frequencies) > 1:
                min_freq = frequencies.min()
                max_freq = frequencies.max()
                
                if max_freq > min_freq:
                    normalized_weights = 0.1 + 0.9 * (frequencies - min_freq) / (max_freq - min_freq)
                else:
                    normalized_weights = pd.Series(0.5, index=frequencies.index)
            else:
                normalized_weights = pd.Series(0.5, index=frequencies.index)
            
            return {
                'weights': normalized_weights.to_dict(),
                'frequencies': frequencies.to_dict(),
                'counts': counts.to_dict()
            }
        
        except Exception as e:
            raise Exception(f"Risk weight calculation error: {str(e)}")
    
    def calculate_composite_risk_score(self, df, entity_col, region_col, value_col=None):
        """
        Calculate composite risk score combining multiple factors
        
        Risk Score = (Entity Weight + Region Weight + Value Weight) / 3
        """
        
        df = df.copy()
        
        try:
            # Get individual weights
            entity_weights = self.calculate_statistical_weights(df, entity_col)['weights']
            region_weights = self.calculate_statistical_weights(df, region_col)['weights']
            
            # Initialize composite risk score
            df['composite_risk'] = 0.0
            
            # Apply entity weights
            for entity, weight in entity_weights.items():
                df.loc[df[entity_col] == entity, 'composite_risk'] += weight
            
            # Apply region weights
            for region, weight in region_weights.items():
                df.loc[df[region_col] == region, 'composite_risk'] += weight
            
            # Apply value-based weighting if available
            if value_col and value_col in df.columns:
                numeric_values = pd.to_numeric(df[value_col], errors='coerce')
                if numeric_values.notna().sum() > 0:
                    min_val = numeric_values.min()
                    max_val = numeric_values.max()
                    
                    if max_val > min_val:
                        value_weight = 0.1 + 0.9 * (numeric_values - min_val) / (max_val - min_val)
                        df.loc[numeric_values.notna(), 'composite_risk'] += value_weight[numeric_values.notna()]
                    else:
                        df['composite_risk'] += 0.5
                
                # Average the scores
                df['composite_risk'] = df['composite_risk'] / 3
            else:
                # Average entity and region weights
                df['composite_risk'] = df['composite_risk'] / 2
            
            # Normalize to 0-1 range
            min_score = df['composite_risk'].min()
            max_score = df['composite_risk'].max()
            
            if max_score > min_score:
                df['composite_risk'] = (df['composite_risk'] - min_score) / (max_score - min_score)
            else:
                df['composite_risk'] = 0.5
            
            return df
        
        except Exception as e:
            raise Exception(f"Composite risk calculation error: {str(e)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MONETARY UNIT SAMPLING (MUS)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def monetary_unit_sampling(self, df, sample_size, value_col, confidence_level=95):
        """
        Monetary Unit Sampling (MUS) - Value-based sampling
        
        Selects units with probability proportional to their monetary value
        Recommended for: High-value transaction populations
        """
        
        df = df.copy()
        sample_size = int(sample_size)
        
        try:
            # Convert value column to numeric
            df[value_col] = pd.to_numeric(df[value_col], errors='coerce')
            df = df.dropna(subset=[value_col])
            
            if len(df) == 0:
                raise ValueError("No valid values after conversion")
            
            # Calculate population value
            total_value = df[value_col].sum()
            
            if total_value <= 0:
                raise ValueError("Total population value must be positive")
            
            # Calculate sampling interval
            sampling_interval = total_value / sample_size
            
            # Create cumulative values
            df['cumulative_value'] = df[value_col].cumsum()
            
            # Generate random starting point
            random_start = np.random.uniform(0, sampling_interval)
            
            # Identify items to sample
            mus_points = np.arange(random_start, total_value, sampling_interval)
            
            sampled_items = []
            for point in mus_points:
                selected = df[df['cumulative_value'] >= point].iloc[0:1]
                if len(selected) > 0:
                    sampled_items.append(selected)
            
            if sampled_items:
                mus_sample = pd.concat(sampled_items).drop_duplicates(subset=df.columns.difference(['cumulative_value']))
            else:
                mus_sample = df.sample(n=min(sample_size, len(df)), random_state=42)
            
            # Remove temporary columns
            mus_sample = mus_sample.drop(columns=['cumulative_value'], errors='ignore')
            
            return mus_sample.head(sample_size), {
                'total_population_value': total_value,
                'sampling_interval': sampling_interval,
                'sample_size': len(mus_sample),
                'confidence_level': confidence_level,
                'method': 'Monetary Unit Sampling'
            }
        
        except Exception as e:
            raise Exception(f"MUS error: {str(e)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COCHRAN FORMULA - SAMPLE SIZE DETERMINATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calculate_cochran_sample_size(self, population_size, confidence_level, 
                                      margin_error, estimated_std=None):
        """Cochran Formula for sample size determination"""
        
        z_scores = {
            80: 1.282, 85: 1.440, 90: 1.645,
            95: 1.960, 97.5: 2.240, 99: 2.576
        }
        
        z = z_scores.get(int(confidence_level), 1.960)
        p = 0.5
        n0 = (z ** 2 * p * (1 - p)) / (margin_error ** 2)
        
        if population_size > 0:
            n = n0 / (1 + (n0 / population_size))
        else:
            n = n0
        
        return {
            'sample_size': int(math.ceil(n)),
            'formula': 'Cochran',
            'confidence': confidence_level,
            'z_score': z,
            'margin_error': margin_error,
            'population': population_size,
            'finite_correction': population_size > 0
        }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ENHANCED ANOMALY DETECTION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def detect_anomalies_advanced(self, df, contamination=0.1):
        """Advanced anomaly detection using multiple factors"""
        
        df = df.copy()
        
        try:
            numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) == 0:
                df['_anomaly_score'] = 0
                return df
            
            # Standardize features
            scaler = StandardScaler()
            scaled_features = scaler.fit_transform(df[numeric_cols].fillna(0))
            
            # Apply Isolation Forest
            iso_forest = IsolationForest(contamination=contamination, random_state=42, n_estimators=100)
            anomaly_labels = iso_forest.fit_predict(scaled_features)
            
            df['_is_anomaly'] = (anomaly_labels == -1)
            df['_anomaly_score'] = iso_forest.score_samples(scaled_features)
            
            return df
        
        except Exception as e:
            print(f"Anomaly detection error: {e}")
            df['_is_anomaly'] = False
            df['_anomaly_score'] = 0
            return df
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ENHANCED STRATIFIED SAMPLING WITH RISK WEIGHTING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def stratified_risk_sampling_enhanced(self, df, sample_size, strata_cols, value_col=None):
        """Enhanced stratified sampling using statistical risk weights"""
        
        df = df.copy()
        sample_size = int(sample_size)
        
        try:
            # Add composite risk scores if value column available
            if value_col and value_col in df.columns:
                entity_col = strata_cols[0] if len(strata_cols) > 0 else None
                region_col = strata_cols[1] if len(strata_cols) > 1 else None
                
                if entity_col and region_col:
                    df = self.calculate_composite_risk_score(df, entity_col, region_col, value_col)
                    risk_col = 'composite_risk'
                else:
                    risk_col = value_col
            else:
                risk_col = 'risk_score' if 'risk_score' in df.columns else strata_cols[0]
            
            # Group by strata
            groups = df.groupby(strata_cols, observed=True)
            total_pop = len(df)
            
            samples = []
            allocation_table = []
            
            for stratum_name, group_df in groups:
                n_h = len(group_df)
                
                # Calculate risk score for stratum
                if risk_col in group_df.columns:
                    stratum_risk = group_df[risk_col].mean()
                else:
                    stratum_risk = math.log(n_h + 1)
                
                # Risk-weighted allocation
                allocation_table.append({
                    'stratum': str(stratum_name),
                    'population': n_h,
                    'risk_score': round(stratum_risk, 4),
                    'risk_pct': round((stratum_risk / total_pop) * 100 if total_pop > 0 else 0, 2)
                })
            
            # Calculate total risk weight
            total_risk = sum(item['risk_score'] * item['population'] for item in allocation_table)
            
            # Allocate samples proportional to risk
            for item in allocation_table:
                if total_risk > 0:
                    weight = (item['risk_score'] * item['population']) / total_risk
                    allocated = max(1, int(weight * sample_size))
                else:
                    allocated = max(1, int(item['population'] / len(allocation_table)))
                
                allocated = min(allocated, item['population'])
                item['allocated'] = allocated
                
                # Get stratum group and sample
                stratum_key = item['stratum']
                stratum_group = groups.get_group(tuple(stratum_key.split(', ')) if ', ' in stratum_key else stratum_key)
                
                if allocated > 0:
                    samples.append(stratum_group.sample(n=allocated, random_state=42))
            
            # Combine samples
            if samples:
                final_sample = pd.concat(samples).drop_duplicates()
                final_sample = final_sample.head(sample_size)
            else:
                final_sample = df.sample(n=min(sample_size, len(df)), random_state=42)
            
            return final_sample, allocation_table
        
        except Exception as e:
            raise Exception(f"Enhanced stratified sampling error: {str(e)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # HYBRID SAMPLING WITH MULTIPLE FACTORS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def hybrid_enhanced_sampling(self, df, sample_size, strata_cols, value_col=None):
        """Hybrid sampling: 50% Risk-Based + 30% Value-Based (MUS) + 20% Anomaly"""
        
        df = df.copy()
        sample_size = int(sample_size)
        
        try:
            risk_size = int(sample_size * 0.50)
            value_size = int(sample_size * 0.30) if value_col else 0
            anomaly_size = int(sample_size * 0.20)
            
            samples = []
            
            # 50% Risk-based stratified
            if risk_size > 0:
                risk_sample, _ = self.stratified_risk_sampling_enhanced(df, risk_size, strata_cols, value_col)
                samples.append(risk_sample)
            
            # 30% Monetary Unit Sampling (if value column available)
            if value_size > 0 and value_col and value_col in df.columns:
                try:
                    mus_sample, _ = self.monetary_unit_sampling(df, value_size, value_col)
                    samples.append(mus_sample)
                except:
                    pass
            
            # 20% Anomaly detection
            if anomaly_size > 0:
                df_with_anomalies = self.detect_anomalies_advanced(df, contamination=0.1)
                anomalies = df_with_anomalies[df_with_anomalies['_is_anomaly']]
                
                if len(anomalies) > 0:
                    anomaly_sample = anomalies.sample(n=min(anomaly_size, len(anomalies)), random_state=42)
                    samples.append(anomaly_sample)
            
            # Combine and deduplicate
            if samples:
                final_sample = pd.concat(samples).drop_duplicates()
                
                # If still need more, add random
                if len(final_sample) < sample_size:
                    remaining = df[~df.index.isin(final_sample.index)]
                    needed = sample_size - len(final_sample)
                    if len(remaining) > 0:
                        additional = remaining.sample(n=min(needed, len(remaining)), random_state=42)
                        final_sample = pd.concat([final_sample, additional])
                
                return final_sample.head(sample_size)
            else:
                return df.sample(n=min(sample_size, len(df)), random_state=42)
        
        except Exception as e:
            raise Exception(f"Hybrid sampling error: {str(e)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # COVERAGE ANALYSIS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def analyze_coverage(self, df, sample, strata_cols):
        """Coverage analysis - Strata representation"""
        
        try:
            if not strata_cols:
                return {
                    'total_pop': len(df),
                    'sample_size': len(sample),
                    'coverage_pct': (len(sample) / len(df) * 100) if len(df) > 0 else 0
                }
            
            all_strata = set(df.groupby(strata_cols, observed=True).groups.keys())
            sample_strata = set(sample.groupby(strata_cols, observed=True).groups.keys())
            missed = all_strata - sample_strata
            
            coverage = len(sample_strata) / len(all_strata) * 100 if len(all_strata) > 0 else 100
            
            return {
                'total_strata': len(all_strata),
                'covered_strata': len(sample_strata),
                'missed_strata': len(missed),
                'coverage_pct': round(coverage, 2),
                'missed_list': list(missed)[:10]
            }
        except Exception as e:
            return {'error': str(e)}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CONFIDENCE INTERVAL CALCULATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def calculate_confidence_interval(self, sample, confidence_level):
        """Calculate confidence interval for sample mean"""
        
        numeric_cols = sample.select_dtypes(include=[np.number]).columns
        ci_results = {}
        
        for col in numeric_cols:
            values = sample[col].dropna()
            if len(values) > 1:
                mean = values.mean()
                std_err = values.sem()
                
                alpha = (100 - confidence_level) / 2
                z_score = stats.norm.ppf(1 - alpha/100)
                margin = z_score * std_err
                
                ci_results[col] = {
                    'mean': round(mean, 2),
                    'std_dev': round(values.std(), 2),
                    'margin_error': round(margin, 2),
                    'lower_bound': round(mean - margin, 2),
                    'upper_bound': round(mean + margin, 2),
                    'confidence': confidence_level
                }
        
        return ci_results
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ASSESSMENT & POPULATION RISK
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def assess_population_risk(self, df, strata_cols):
        """Risk Assessment following COSO Framework"""
        
        assessment = {
            'total_records': len(df),
            'total_strata': len(df.groupby(strata_cols, observed=True)) if strata_cols else 1,
            'analysis': {}
        }
        
        # Factor 1: Population Variability
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            cv_scores = []
            for col in numeric_cols:
                mean = df[col].mean()
                if mean != 0:
                    cv = df[col].std() / abs(mean)
                    cv_scores.append(cv)
            
            avg_cv = np.mean(cv_scores) if cv_scores else 0
            
            if avg_cv < 0.5:
                variability_risk = 'Very Low'
            elif avg_cv < 1.0:
                variability_risk = 'Low'
            elif avg_cv < 1.5:
                variability_risk = 'Medium'
            elif avg_cv < 2.0:
                variability_risk = 'High'
            else:
                variability_risk = 'Very High'
            
            assessment['analysis']['population_variability'] = {
                'coefficient_variation': round(avg_cv, 2),
                'risk_level': variability_risk
            }
        
        # Factor 2: Data Quality
        missing_pct = (df.isna().sum().sum() / (len(df) * len(df.columns))) * 100
        
        if missing_pct < 0.1:
            quality_risk = 'Very Low'
        elif missing_pct < 1:
            quality_risk = 'Low'
        elif missing_pct < 5:
            quality_risk = 'Medium'
        elif missing_pct < 10:
            quality_risk = 'High'
        else:
            quality_risk = 'Very High'
        
        assessment['analysis']['data_quality'] = {
            'missing_percent': round(missing_pct, 2),
            'risk_level': quality_risk
        }
        
        # Overall Risk Level
        risk_levels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']
        risk_scores = {
            'Very Low': 1, 'Low': 2, 'Medium': 3, 'High': 4, 'Very High': 5
        }
        
        scores = []
        for factor in assessment['analysis'].values():
            scores.append(risk_scores.get(factor['risk_level'], 3))
        
        overall_score = np.mean(scores) if scores else 3
        
        if overall_score <= 1.5:
            overall_risk = 'Very Low'
        elif overall_score <= 2.5:
            overall_risk = 'Low'
        elif overall_score <= 3.5:
            overall_risk = 'Medium'
        elif overall_score <= 4.5:
            overall_risk = 'High'
        else:
            overall_risk = 'Very High'
        
        assessment['overall_risk'] = overall_risk
        assessment['risk_score'] = round(overall_score, 2)
        
        self.risk_assessment = assessment
        return assessment


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PROFESSIONAL TKINTER APPLICATION (EXTENDED UI)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProfessionalAuditApp:
    """Enhanced professional-grade audit sampling application"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("Professional Audit Sampling Tool v6.5")
        self.root.geometry("1900x1100")
        self.root.minsize(1700, 1000)
        
        self.engine = EnhancedAuditEngine()
        self.data = None
        self.samples = {}
        self.strata_cols = []
        self.additional_cols = []
        self.risk_assessment = {}
        self.value_column = None
        
        style = ttk.Style()
        style.theme_use('clam')
        
        self.build_ui()
    
    def build_ui(self):
        """Build main UI - KEEPING EXISTING STRUCTURE, ADDING NEW TABS"""
        main = ttk.Frame(self.root)
        main.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Header
        header = ttk.Frame(main)
        header.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Label(header, text="ğŸ›ï¸ Professional Audit Sampling Tool v6.5", 
                 font=('Arial', 16, 'bold')).pack(side=tk.LEFT)
        ttk.Label(header, text="AICPA | ISA 530 | IIA | MUS | Risk Weighting", 
                 font=('Arial', 9, 'italic'), foreground='gray').pack(side=tk.LEFT, padx=20)
        
        # Notebook with 8 pages (original 6 + 2 new)
        self.notebook = ttk.Notebook(main)
        self.notebook.pack(fill=tk.BOTH, expand=True)
        
        self.pages = {}
        page_names = [
            ("ğŸ“‚ Data Loading", "page_load"),
            ("ğŸ“Š Data Analysis", "page_analysis"),
            ("âš™ï¸ Configuration", "page_config"),
            ("ğŸ“ˆ Risk Assessment", "page_risk"),
            ("ğŸ² Sampling", "page_sampling"),
            ("ğŸ’¾ Export & Report", "page_export"),
            ("ğŸ’° MUS Analysis", "page_mus"),  # NEW
            ("ğŸ“Š Risk Weighting", "page_weights")  # NEW
        ]
        
        for label, name in page_names:
            page = ttk.Frame(self.notebook)
            self.notebook.add(page, text=label)
            self.pages[name] = page
        
        # Build original pages
        self.build_page_load()
        self.build_page_analysis()
        self.build_page_config()
        self.build_page_risk()
        self.build_page_sampling()
        self.build_page_export()
        
        # Build new pages
        self.build_page_mus()
        self.build_page_weights()
    
    def build_page_load(self):
        """Page 1: Data Loading (SAME AS v6.0)"""
        f = ttk.Frame(self.pages['page_load'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        load_frame = ttk.LabelFrame(f, text="Data Source", padding=10)
        load_frame.pack(fill=tk.X, pady=(0, 20))
        
        btn_frame = ttk.Frame(load_frame)
        btn_frame.pack(fill=tk.X)
        
        ttk.Button(btn_frame, text="ğŸ“ Load CSV/Excel", 
                  command=self.load_file).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ² Generate Demo", 
                  command=self.generate_demo).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ”„ Reload", 
                  command=self.reload_data).pack(side=tk.LEFT, padx=5)
        
        self.status_label = ttk.Label(load_frame, text="â³ No data loaded", 
                                      font=('Arial', 10))
        self.status_label.pack(side=tk.LEFT, padx=20)
        
        stats_frame = ttk.LabelFrame(f, text="Data Statistics", padding=10)
        stats_frame.pack(fill=tk.X, pady=(0, 20))
        
        self.stats_text = scrolledtext.ScrolledText(stats_frame, height=8, width=100,
                                                    font=('Courier', 9))
        self.stats_text.pack(fill=tk.BOTH, expand=True)
        
        prev_frame = ttk.LabelFrame(f, text="Data Preview (First 50 Rows)", padding=10)
        prev_frame.pack(fill=tk.BOTH, expand=True)
        
        scroll_y = ttk.Scrollbar(prev_frame)
        scroll_x = ttk.Scrollbar(prev_frame, orient=tk.HORIZONTAL)
        
        self.preview_tree = ttk.Treeview(prev_frame, 
                                         yscrollcommand=scroll_y.set,
                                         xscrollcommand=scroll_x.set)
        
        scroll_y.config(command=self.preview_tree.yview)
        scroll_x.config(command=self.preview_tree.xview)
        
        self.preview_tree.grid(row=0, column=0, sticky='nsew')
        scroll_y.grid(row=0, column=1, sticky='ns')
        scroll_x.grid(row=1, column=0, sticky='ew')
        
        prev_frame.columnconfigure(0, weight=1)
        prev_frame.rowconfigure(0, weight=1)
    
    def build_page_analysis(self):
        """Page 2: Data Analysis (SAME AS v6.0)"""
        f = ttk.Frame(self.pages['page_analysis'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        btn_frame = ttk.Frame(f)
        btn_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(btn_frame, text="ğŸ” Analyze Data", 
                  command=self.analyze_data).pack(side=tk.LEFT, padx=5)
        
        analysis_nb = ttk.Notebook(f)
        analysis_nb.pack(fill=tk.BOTH, expand=True)
        
        stats_tab = ttk.Frame(analysis_nb)
        analysis_nb.add(stats_tab, text="Statistics")
        
        self.analysis_text = scrolledtext.ScrolledText(stats_tab, height=30, width=150,
                                                       font=('Courier', 9))
        self.analysis_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        charts_tab = ttk.Frame(analysis_nb)
        analysis_nb.add(charts_tab, text="Charts")
        
        self.analysis_canvas_frame = ttk.Frame(charts_tab)
        self.analysis_canvas_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def build_page_config(self):
        """Page 3: Sampling Configuration (EXTENDED WITH VALUE COLUMN)"""
        f = ttk.Frame(self.pages['page_config'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        strat_frame = ttk.LabelFrame(f, text="Stratification Columns", padding=10)
        strat_frame.pack(fill=tk.X, pady=(0, 20))
        
        col_grid = ttk.Frame(strat_frame)
        col_grid.pack(fill=tk.X)
        
        for i, label in enumerate(['Column 1:*', 'Column 2:*', 'Column 3:*']):
            ttk.Label(col_grid, text=label, font=('Arial', 9, 'bold')).grid(row=0, column=i*2, padx=5)
            combo = ttk.Combobox(col_grid, width=22, state='readonly')
            combo.grid(row=0, column=i*2+1, padx=5)
            setattr(self, f'col{i+1}', combo)
        
        self.col_status = ttk.Label(strat_frame, text="âš ï¸ Select columns", 
                                   foreground='red', font=('Arial', 9))
        self.col_status.pack(pady=10)
        
        add_frame = ttk.LabelFrame(f, text="Optional Columns", padding=10)
        add_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(add_frame, text="â• Add Columns", 
                  command=self.add_columns).pack(anchor=tk.W, padx=5)
        
        self.add_label = ttk.Label(add_frame, text="None selected", foreground='gray')
        self.add_label.pack(anchor=tk.W, padx=5, pady=5)
        
        # NEW: Value column selector for MUS
        value_frame = ttk.LabelFrame(f, text="Value Column (For MUS & Weighting)", padding=10)
        value_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Label(value_frame, text="Value/Amount Column:").pack(side=tk.LEFT, padx=5)
        self.value_col_combo = ttk.Combobox(value_frame, width=25, state='readonly')
        self.value_col_combo.pack(side=tk.LEFT, padx=5)
        
        param_frame = ttk.LabelFrame(f, text="Sampling Parameters", padding=10)
        param_frame.pack(fill=tk.X)
        
        param_grid = ttk.Frame(param_frame)
        param_grid.pack(fill=tk.X)
        
        params = [
            ('Sample Size:', 'sample_size', 1247),
            ('Confidence Level (%):', 'confidence', 95),
            ('Margin of Error:', 'margin_error', 0.05),
            ('Population Risk:', 'pop_risk', 'Medium'),
            ('Anomaly Contamination (%):', 'contamination', 5),  # NEW
        ]
        
        row = 0
        for label, attr, default in params:
            ttk.Label(param_grid, text=label).grid(row=row, column=0, padx=5, pady=5)
            
            if attr == 'pop_risk':
                combo = ttk.Combobox(param_grid, width=15, state='readonly',
                                   values=['Very Low', 'Low', 'Medium', 'High', 'Very High'])
                combo.set(default)
                combo.grid(row=row, column=1, padx=5)
                setattr(self, attr, combo)
            else:
                spin = ttk.Spinbox(param_grid, width=15)
                spin.set(default)
                spin.grid(row=row, column=1, padx=5)
                setattr(self, attr, spin)
            
            row += 1
    
    def build_page_risk(self):
        """Page 4: Risk Assessment (SAME AS v6.0)"""
        f = ttk.Frame(self.pages['page_risk'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        btn_frame = ttk.Frame(f)
        btn_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(btn_frame, text="ğŸ“Š Assess Risk", 
                  command=self.assess_risk).pack(side=tk.LEFT, padx=5)
        
        risk_nb = ttk.Notebook(f)
        risk_nb.pack(fill=tk.BOTH, expand=True)
        
        assess_tab = ttk.Frame(risk_nb)
        risk_nb.add(assess_tab, text="Risk Assessment")
        
        self.risk_text = scrolledtext.ScrolledText(assess_tab, height=30, width=150,
                                                   font=('Courier', 9))
        self.risk_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        heat_tab = ttk.Frame(risk_nb)
        risk_nb.add(heat_tab, text="Risk Heat Map")
        
        self.heat_frame = ttk.Frame(heat_tab)
        self.heat_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def build_page_sampling(self):
        """Page 5: Sampling Execution (EXTENDED WITH MUS & HYBRID)"""
        f = ttk.Frame(self.pages['page_sampling'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        method_frame = ttk.LabelFrame(f, text="Sampling Methods", padding=10)
        method_frame.pack(fill=tk.X, pady=(0, 20))
        
        self.use_stratified = tk.BooleanVar(value=True)
        self.use_mus = tk.BooleanVar(value=False)  # NEW
        self.use_hybrid = tk.BooleanVar(value=False)
        self.use_attribute = tk.BooleanVar(value=False)
        
        ttk.Checkbutton(method_frame, text="âœ“ Stratified Risk-Based", 
                       variable=self.use_stratified).pack(anchor=tk.W, padx=10, pady=3)
        ttk.Checkbutton(method_frame, text="âœ“ Monetary Unit Sampling (MUS)", 
                       variable=self.use_mus).pack(anchor=tk.W, padx=10, pady=3)
        ttk.Checkbutton(method_frame, text="âœ“ Hybrid Enhanced (50% Risk + 30% MUS + 20% Anomaly)", 
                       variable=self.use_hybrid).pack(anchor=tk.W, padx=10, pady=3)
        ttk.Checkbutton(method_frame, text="âœ“ Attribute Sampling", 
                       variable=self.use_attribute).pack(anchor=tk.W, padx=10, pady=3)
        
        ttk.Button(method_frame, text="â–¶ï¸ Generate Samples", 
                  command=self.generate_samples).pack(pady=20)
        
        results_nb = ttk.Notebook(f)
        results_nb.pack(fill=tk.BOTH, expand=True)
        
        result_tab = ttk.Frame(results_nb)
        results_nb.add(result_tab, text="Results")
        
        self.result_text = scrolledtext.ScrolledText(result_tab, height=25, width=150,
                                                     font=('Courier', 9))
        self.result_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        alloc_tab = ttk.Frame(results_nb)
        results_nb.add(alloc_tab, text="Sample Allocation")
        
        self.alloc_frame = ttk.Frame(alloc_tab)
        self.alloc_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        cov_tab = ttk.Frame(results_nb)
        results_nb.add(cov_tab, text="Coverage Analysis")
        
        self.coverage_text = scrolledtext.ScrolledText(cov_tab, height=25, width=150,
                                                      font=('Courier', 9))
        self.coverage_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def build_page_export(self):
        """Page 6: Export & Reporting (SAME AS v6.0)"""
        f = ttk.Frame(self.pages['page_export'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        btn_frame = ttk.LabelFrame(f, text="Export Options", padding=10)
        btn_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(btn_frame, text="ğŸ’¾ Export All", 
                  command=self.export_all).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ“„ Generate Audit Report", 
                  command=self.generate_audit_report).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ“Š Export Summary", 
                  command=self.export_summary).pack(side=tk.LEFT, padx=5)
        ttk.Button(btn_frame, text="ğŸ“‹ Export Risk Weights", 
                  command=self.export_risk_weights).pack(side=tk.LEFT, padx=5)  # NEW
        
        log_frame = ttk.LabelFrame(f, text="Export Log & Reports", padding=10)
        log_frame.pack(fill=tk.BOTH, expand=True)
        
        self.export_text = scrolledtext.ScrolledText(log_frame, height=30, width=150,
                                                     font=('Courier', 9))
        self.export_text.pack(fill=tk.BOTH, expand=True)
    
    def build_page_mus(self):
        """Page 7: MUS Analysis (NEW PAGE)"""
        f = ttk.Frame(self.pages['page_mus'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        btn_frame = ttk.Frame(f)
        btn_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(btn_frame, text="ğŸ’° Analyze MUS", 
                  command=self.analyze_mus).pack(side=tk.LEFT, padx=5)
        
        mus_nb = ttk.Notebook(f)
        mus_nb.pack(fill=tk.BOTH, expand=True)
        
        stats_tab = ttk.Frame(mus_nb)
        mus_nb.add(stats_tab, text="MUS Statistics")
        
        self.mus_text = scrolledtext.ScrolledText(stats_tab, height=30, width=150,
                                                  font=('Courier', 9))
        self.mus_text.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        chart_tab = ttk.Frame(mus_nb)
        mus_nb.add(chart_tab, text="Value Distribution")
        
        self.mus_chart_frame = ttk.Frame(chart_tab)
        self.mus_chart_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    def build_page_weights(self):
        """Page 8: Risk Weighting Analysis (NEW PAGE)"""
        f = ttk.Frame(self.pages['page_weights'], padding=15)
        f.pack(fill=tk.BOTH, expand=True)
        
        btn_frame = ttk.Frame(f)
        btn_frame.pack(fill=tk.X, pady=(0, 20))
        
        ttk.Button(btn_frame, text="ğŸ“Š Calculate Risk Weights", 
                  command=self.calculate_risk_weights).pack(side=tk.LEFT, padx=5)
        
        weights_nb = ttk.Notebook(f)
        weights_nb.pack(fill=tk.BOTH, expand=True)
        
        weights_tab = ttk.Frame(weights_nb)
        weights_nb.add(weights_tab, text="Risk Weights")
        
        self.weights_tree = ttk.Treeview(weights_tab, columns=('Category', 'Count', 'Frequency %', 'Risk Weight'), height=25)
        self.weights_tree.heading('#0', text='Item')
        self.weights_tree.heading('Category', text='Category')
        self.weights_tree.heading('Count', text='Exception Count')
        self.weights_tree.heading('Frequency %', text='Frequency %')
        self.weights_tree.heading('Risk Weight', text='Risk Weight (0.1-1.0)')
        
        self.weights_tree.column('#0', width=150)
        self.weights_tree.column('Category', width=150)
        self.weights_tree.column('Count', width=120)
        self.weights_tree.column('Frequency %', width=120)
        self.weights_tree.column('Risk Weight', width=150)
        
        self.weights_tree.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
        
        chart_tab = ttk.Frame(weights_nb)
        weights_nb.add(chart_tab, text="Weight Distribution")
        
        self.weights_chart_frame = ttk.Frame(chart_tab)
        self.weights_chart_frame.pack(fill=tk.BOTH, expand=True, padx=5, pady=5)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CALLBACKS (ORIGINAL METHODS UNCHANGED, NEW METHODS ADDED)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def load_file(self):
        """Load data file"""
        file = filedialog.askopenfilename(
            filetypes=[("CSV", "*.csv"), ("Excel", "*.xlsx")]
        )
        
        if file:
            try:
                self.data = pd.read_csv(file) if file.endswith('.csv') else pd.read_excel(file)
                self.data = self.engine.sanitize_data(self.data)
                
                self.update_preview()
                self.update_columns()
                self.show_basic_stats()
                
                self.status_label.config(
                    text=f"âœ… Loaded: {len(self.data):,} rows Ã— {len(self.data.columns)} cols",
                    foreground='green'
                )
            except Exception as e:
                messagebox.showerror("Error", f"Load failed: {str(e)}")
    
    def generate_demo(self):
        """Generate demo data with enhanced fields"""
        np.random.seed(42)
        
        n = 50000
        data = {
            'Entity': np.random.choice(['HBAP', 'HBUS', 'GFX', 'IRD', 'GBM'], n),
            'Region': np.random.choice(['LN', 'NY', 'SG', 'HK', 'TYO'], n),
            'Product': np.random.choice(['Equity', 'FX', 'Rates', 'Credit'], n),
            'Amount': np.random.lognormal(10, 2, n),
            'Age_Days': np.random.randint(1, 365, n),
            'Status': np.random.choice(['Active', 'Pending', 'Exception'], n, p=[0.85, 0.10, 0.05]),
            'Exception_Flag': np.random.choice([0, 1], n, p=[0.95, 0.05]),
            'Risk_Score': np.random.uniform(0.1, 0.9, n)  # NEW: for weighting
        }
        
        self.data = pd.DataFrame(data)
        self.update_preview()
        self.update_columns()
        self.show_basic_stats()
        
        self.status_label.config(
            text=f"âœ… Demo: {len(self.data):,} rows Ã— {len(self.data.columns)} cols",
            foreground='green'
        )
    
    def reload_data(self):
        """Reload and refresh data"""
        if self.data is None:
            messagebox.showwarning("Info", "No data loaded")
            return
        
        self.show_basic_stats()
        messagebox.showinfo("Success", "Data refreshed")
    
    def show_basic_stats(self):
        """Show basic statistics"""
        if self.data is None:
            return
        
        stats = f"""
DATASET OVERVIEW
{'='*80}

Total Records: {len(self.data):,}
Total Columns: {len(self.data.columns)}
Column Names: {', '.join(self.data.columns[:10])}{'...' if len(self.data.columns) > 10 else ''}

DATA QUALITY
{'='*80}
Missing Values: {self.data.isna().sum().sum():,} ({(self.data.isna().sum().sum()/(len(self.data)*len(self.data.columns))*100):.2f}%)
Duplicate Rows: {self.data.duplicated().sum():,}
Memory Usage: {self.data.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB

NUMERIC COLUMNS SUMMARY
{'='*80}
"""
        
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns
        for col in numeric_cols[:5]:
            stats += f"\n{col}:\n"
            stats += f"  Mean: {self.data[col].mean():.2f} | Median: {self.data[col].median():.2f}\n"
            stats += f"  Min: {self.data[col].min():.2f} | Max: {self.data[col].max():.2f}\n"
            stats += f"  Std Dev: {self.data[col].std():.2f}\n"
        
        if len(numeric_cols) > 5:
            stats += f"\n... and {len(numeric_cols)-5} more numeric columns\n"
        
        self.stats_text.delete('1.0', tk.END)
        self.stats_text.insert('1.0', stats)
    
    def update_preview(self):
        """Update data preview"""
        for item in self.preview_tree.get_children():
            self.preview_tree.delete(item)
        
        if self.data is None:
            return
        
        cols = list(self.data.columns)[:12]
        self.preview_tree['columns'] = cols
        self.preview_tree['show'] = 'headings'
        
        for col in cols:
            self.preview_tree.heading(col, text=col)
            self.preview_tree.column(col, width=90)
        
        for _, row in self.data.head(50).iterrows():
            vals = [str(row[c])[:50] for c in cols]
            self.preview_tree.insert('', tk.END, values=vals)
    
    def update_columns(self):
        """Update column dropdowns"""
        if self.data is None:
            return
        
        cols = [''] + list(self.data.columns)
        self.col1['values'] = cols
        self.col2['values'] = cols
        self.col3['values'] = cols
        self.value_col_combo['values'] = cols  # NEW
    
    def add_columns(self):
        """Add optional columns"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        used = {self.col1.get(), self.col2.get(), self.col3.get()}
        available = [c for c in self.data.columns if c not in used]
        
        win = tk.Toplevel(self.root)
        win.title("Select Additional Columns")
        win.geometry("450x450")
        
        ttk.Label(win, text="Select columns for additional stratification (Ctrl+Click):", 
                 font=('Arial', 10)).pack(pady=10)
        
        scroll = ttk.Scrollbar(win)
        scroll.pack(side=tk.RIGHT, fill=tk.Y)
        
        listbox = tk.Listbox(win, yscrollcommand=scroll.set, selectmode=tk.MULTIPLE,
                            font=('Arial', 10))
        listbox.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        scroll.config(command=listbox.yview)
        
        for col in available:
            listbox.insert(tk.END, col)
        
        def confirm():
            self.additional_cols = [available[i] for i in listbox.curselection()]
            if self.additional_cols:
                self.add_label.config(text=f"Selected: {len(self.additional_cols)}", 
                                     foreground='blue')
            win.destroy()
        
        ttk.Button(win, text="âœ… Confirm", command=confirm).pack(pady=10)
    
    def analyze_data(self):
        """Analyze data"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        try:
            output = f"""
DATA ANALYSIS REPORT
{'='*80}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

DESCRIPTIVE STATISTICS
{'='*80}
"""
            
            numeric_cols = self.data.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                output += f"\n{col}:\n"
                output += f"  Count: {self.data[col].count():,}\n"
                output += f"  Mean: {self.data[col].mean():.4f}\n"
                output += f"  Median: {self.data[col].median():.4f}\n"
                output += f"  Std Dev: {self.data[col].std():.4f}\n"
                output += f"  Min: {self.data[col].min():.4f}\n"
                output += f"  Max: {self.data[col].max():.4f}\n"
            
            self.analysis_text.delete('1.0', tk.END)
            self.analysis_text.insert('1.0', output)
            
            self.generate_analysis_charts()
            
        except Exception as e:
            messagebox.showerror("Error", f"Analysis failed: {str(e)}")
    
    def generate_analysis_charts(self):
        """Generate analysis charts"""
        try:
            for widget in self.analysis_canvas_frame.winfo_children():
                widget.destroy()
            
            numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) < 2:
                return
            
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
            fig.suptitle('Data Analysis Dashboard', fontsize=14, fontweight='bold')
            
            axes[0, 0].hist(self.data[numeric_cols[0]], bins=50, color='steelblue', edgecolor='black')
            axes[0, 0].set_title(f'Distribution: {numeric_cols[0]}')
            axes[0, 0].set_ylabel('Frequency')
            
            self.data[[c for c in numeric_cols if c in self.data.columns][:4]].boxplot(ax=axes[0, 1])
            axes[0, 1].set_title('Box Plot (Numeric Columns)')
            axes[0, 1].set_ylabel('Value')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            if len(numeric_cols) >= 2:
                axes[1, 0].scatter(self.data[numeric_cols[0]], self.data[numeric_cols[1]], 
                                 alpha=0.5, s=20)
                axes[1, 0].set_title(f'{numeric_cols[0]} vs {numeric_cols[1]}')
                axes[1, 0].set_xlabel(numeric_cols[0])
                axes[1, 0].set_ylabel(numeric_cols[1])
            
            if len(numeric_cols) > 1:
                corr = self.data[numeric_cols[:5]].corr()
                im = axes[1, 1].imshow(corr, cmap='coolwarm', aspect='auto')
                axes[1, 1].set_title('Correlation Matrix')
                axes[1, 1].set_xticks(range(len(corr.columns)))
                axes[1, 1].set_yticks(range(len(corr.columns)))
                axes[1, 1].set_xticklabels(corr.columns, rotation=45, ha='right')
                axes[1, 1].set_yticklabels(corr.columns)
                plt.colorbar(im, ax=axes[1, 1])
            
            plt.tight_layout()
            
            canvas = FigureCanvasTkAgg(fig, master=self.analysis_canvas_frame)
            canvas.draw()
            canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            
        except Exception as e:
            print(f"Chart error: {e}")
    
    def validate_config(self):
        """Validate configuration"""
        c1, c2, c3 = self.col1.get(), self.col2.get(), self.col3.get()
        
        if not c1 or not c2 or not c3:
            self.col_status.config(text="âš ï¸ Select all mandatory columns", foreground='red')
            return False
        
        if len({c1, c2, c3}) != 3:
            self.col_status.config(text="âš ï¸ Columns must be different", foreground='red')
            return False
        
        self.col_status.config(text="âœ… Valid configuration", foreground='green')
        self.strata_cols = [c1, c2, c3] + self.additional_cols
        self.value_column = self.value_col_combo.get() if self.value_col_combo.get() else None
        return True
    
    def assess_risk(self):
        """Assess population risk"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        if not self.validate_config():
            return
        
        try:
            risk = self.engine.assess_population_risk(self.data, self.strata_cols)
            
            output = f"""
RISK ASSESSMENT REPORT
{'='*80}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

OVERALL RISK LEVEL: {risk.get('overall_risk', 'N/A')} (Score: {risk.get('risk_score', 'N/A')})

DETAILED ANALYSIS
{'='*80}
"""
            
            for factor, analysis in risk.get('analysis', {}).items():
                output += f"\n{factor.upper()}\n"
                output += "-" * 80 + "\n"
                for key, value in analysis.items():
                    output += f"  {key}: {value}\n"
            
            output += f"\n{'='*80}\nRECOMMENDATIONS\n"
            output += "-" * 80 + "\n"
            
            risk_level = risk.get('overall_risk', 'Medium')
            if risk_level == 'Very Low':
                output += "âœ… Low risk population. Standard sampling approach recommended.\n"
            elif risk_level == 'Low':
                output += "âœ… Low-moderate risk. Standard approach recommended.\n"
            elif risk_level == 'Medium':
                output += "âš ï¸ Moderate risk. Stratified sampling recommended.\n"
            elif risk_level == 'High':
                output += "âš ï¸ High risk. Enhanced sampling recommended.\n"
            else:
                output += "ğŸ”´ Very high risk. Maximum testing recommended.\n"
            
            self.risk_text.delete('1.0', tk.END)
            self.risk_text.insert('1.0', output)
            
            self.risk_assessment = risk
            messagebox.showinfo("Success", "Risk assessment complete")
            
        except Exception as e:
            messagebox.showerror("Error", f"Risk assessment failed: {str(e)}")
    
    def generate_samples(self):
        """Generate samples with MUS and hybrid methods"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        if not self.validate_config():
            return
        
        try:
            size = int(self.sample_size.get())
            confidence = int(self.confidence.get())
            
            cochran = self.engine.calculate_cochran_sample_size(
                len(self.data), confidence, float(self.margin_error.get())
            )
            
            self.result_text.delete('1.0', tk.END)
            
            output = f"""
AUDIT SAMPLING EXECUTION
{'='*80}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

SAMPLE SIZE DETERMINATION (COCHRAN FORMULA)
{'='*80}
Population Size: {cochran['population']:,}
Confidence Level: {cochran['confidence']}%
Margin of Error: {cochran['margin_error']}
Z-Score: {cochran['z_score']:.4f}
Calculated Sample Size: {cochran['sample_size']:,}
User-Specified Sample Size: {size:,}
Final Sample Size: {min(size, cochran['sample_size']):,}

REGULATORY COMPLIANCE
{'='*80}
âœ… Follows AICPA AU-C Section 530
âœ… Compliant with ISA 530
âœ… IIA Standards Compliance
âœ… COSO Framework Risk Assessment
âœ… MUS & Risk Weighting Applied

SAMPLING EXECUTION
{'='*80}
"""
            
            self.samples = {}
            
            # Stratified sampling
            if self.use_stratified.get():
                output += "\nâ–¶ STRATIFIED RISK-BASED SAMPLING\n"
                output += "-" * 80 + "\n"
                try:
                    sample, allocation = self.engine.stratified_risk_sampling_enhanced(
                        self.data, size, self.strata_cols, self.value_column
                    )
                    
                    self.samples['Stratified'] = sample
                    output += f"  Sample Size: {len(sample):,}\n"
                    output += f"  Strata Covered: {len(allocation)}\n"
                    output += f"  Status: âœ… SUCCESS\n\n"
                    
                    self.show_allocation_table(allocation)
                    
                except Exception as e:
                    output += f"  âŒ Error: {str(e)}\n\n"
            
            # MUS
            if self.use_mus.get():
                output += "â–¶ MONETARY UNIT SAMPLING (MUS)\n"
                output += "-" * 80 + "\n"
                try:
                    if not self.value_column:
                        output += "  âš ï¸ Value column not selected\n\n"
                    else:
                        sample, mus_info = self.engine.monetary_unit_sampling(
                            self.data, size, self.value_column, confidence
                        )
                        
                        self.samples['MUS'] = sample
                        output += f"  Sample Size: {len(sample):,}\n"
                        output += f"  Total Population Value: ${mus_info['total_population_value']:,.2f}\n"
                        output += f"  Sampling Interval: ${mus_info['sampling_interval']:,.2f}\n"
                        output += f"  Status: âœ… SUCCESS\n\n"
                
                except Exception as e:
                    output += f"  âŒ Error: {str(e)}\n\n"
            
            # Hybrid
            if self.use_hybrid.get():
                output += "â–¶ HYBRID ENHANCED SAMPLING (50% Risk + 30% MUS + 20% Anomaly)\n"
                output += "-" * 80 + "\n"
                try:
                    sample = self.engine.hybrid_enhanced_sampling(
                        self.data, int(size*1.3), self.strata_cols, self.value_column
                    )
                    
                    self.samples['Hybrid'] = sample
                    output += f"  Sample Size: {len(sample):,}\n"
                    output += f"  Status: âœ… SUCCESS\n\n"
                
                except Exception as e:
                    output += f"  âŒ Error: {str(e)}\n\n"
            
            output += "="*80 + "\nâœ… Sampling complete!\n"
            
            self.result_text.insert('1.0', output)
            messagebox.showinfo("Success", "Sampling completed!")
            
        except Exception as e:
            messagebox.showerror("Error", f"Sampling failed: {str(e)}\n{traceback.format_exc()}")
    
    def show_allocation_table(self, allocation):
        """Show allocation table"""
        for widget in self.alloc_frame.winfo_children():
            widget.destroy()
        
        cols = ('Stratum', 'Population', 'Risk Score', 'Risk %', 'Allocated')
        tree = ttk.Treeview(self.alloc_frame, columns=cols, height=20)
        
        tree.heading('#0', text='#')
        for col in cols:
            tree.heading(col, text=col)
            tree.column(col, width=130)
        
        tree.grid(row=0, column=0, sticky='nsew')
        
        for i, item in enumerate(allocation, 1):
            values = (
                item['stratum'],
                f"{item['population']:,}",
                f"{item['risk_score']:.4f}",
                f"{item.get('risk_pct', 0):.2f}",
                f"{item['allocated']:,}"
            )
            tree.insert('', 'end', text=str(i), values=values)
        
        self.alloc_frame.columnconfigure(0, weight=1)
        self.alloc_frame.rowconfigure(0, weight=1)
    
    def analyze_mus(self):
        """Analyze MUS results"""
        if not self.samples:
            messagebox.showerror("Error", "Generate samples first")
            return
        
        try:
            if 'MUS' not in self.samples:
                messagebox.showerror("Error", "MUS sample not generated")
                return
            
            sample = self.samples['MUS']
            value_col = self.value_column
            
            if not value_col or value_col not in sample.columns:
                messagebox.showerror("Error", "Value column not found in MUS sample")
                return
            
            output = f"""
MONETARY UNIT SAMPLING (MUS) ANALYSIS
{'='*80}
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

SAMPLE SUMMARY
{'='*80}
Sample Size: {len(sample):,}
Average Amount: ${sample[value_col].mean():,.2f}
Median Amount: ${sample[value_col].median():,.2f}
Total Amount: ${sample[value_col].sum():,.2f}
Min Amount: ${sample[value_col].min():,.2f}
Max Amount: ${sample[value_col].max():,.2f}
Std Dev: ${sample[value_col].std():,.2f}

DISTRIBUTION ANALYSIS
{'='*80}
"""
            
            if len(self.strata_cols) > 0 and self.strata_cols[0] in sample.columns:
                output += "\nDistribution by Primary Stratum:\n"
                dist = sample[self.strata_cols[0]].value_counts()
                for item, count in dist.items():
                    pct = (count / len(sample)) * 100
                    output += f"  {item}: {count:,} ({pct:.2f}%)\n"
            
            self.mus_text.delete('1.0', tk.END)
            self.mus_text.insert('1.0', output)
            
            # Generate chart
            self.generate_mus_chart(sample, value_col)
            
        except Exception as e:
            messagebox.showerror("Error", f"MUS analysis failed: {str(e)}")
    
    def generate_mus_chart(self, sample, value_col):
        """Generate MUS value distribution chart"""
        try:
            for widget in self.mus_chart_frame.winfo_children():
                widget.destroy()
            
            fig, axes = plt.subplots(1, 2, figsize=(14, 5))
            fig.suptitle('MUS Value Distribution Analysis', fontsize=14, fontweight='bold')
            
            # Histogram
            axes[0].hist(sample[value_col], bins=50, color='steelblue', edgecolor='black')
            axes[0].set_title('Distribution of Sampled Values')
            axes[0].set_xlabel('Value')
            axes[0].set_ylabel('Frequency')
            axes[0].set_xscale('log')
            
            # Cumulative
            sorted_vals = np.sort(sample[value_col].values)
            cumulative = np.cumsum(sorted_vals)
            axes[1].plot(cumulative)
            axes[1].set_title('Cumulative Value Distribution')
            axes[1].set_xlabel('Sample Order')
            axes[1].set_ylabel('Cumulative Value')
            
            plt.tight_layout()
            
            canvas = FigureCanvasTkAgg(fig, master=self.mus_chart_frame)
            canvas.draw()
            canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            
        except Exception as e:
            print(f"MUS chart error: {e}")
    
    def calculate_risk_weights(self):
        """Calculate statistical risk weights"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        if not self.validate_config():
            return
        
        try:
            entity_col = self.strata_cols[0] if len(self.strata_cols) > 0 else None
            region_col = self.strata_cols[1] if len(self.strata_cols) > 1 else None
            
            if not entity_col or not region_col:
                messagebox.showerror("Error", "Need at least 2 stratification columns")
                return
            
            # Calculate weights
            entity_info = self.engine.calculate_statistical_weights(self.data, entity_col)
            region_info = self.engine.calculate_statistical_weights(self.data, region_col)
            
            self.weights_tree.delete(*self.weights_tree.get_children())
            
            # Entity weights
            parent = self.weights_tree.insert('', 'end', text='LEGAL ENTITIES', values=('', '', '', ''))
            for entity, weight in entity_info['weights'].items():
                count = entity_info['counts'].get(entity, 0)
                freq = entity_info['frequencies'].get(entity, 0) * 100
                self.weights_tree.insert(parent, 'end', text=str(entity), 
                                        values=('Entity', f"{count:,}", f"{freq:.2f}%", f"{weight:.4f}"))
            
            # Regional weights
            parent = self.weights_tree.insert('', 'end', text='REGIONS', values=('', '', '', ''))
            for region, weight in region_info['weights'].items():
                count = region_info['counts'].get(region, 0)
                freq = region_info['frequencies'].get(region, 0) * 100
                self.weights_tree.insert(parent, 'end', text=str(region), 
                                        values=('Region', f"{count:,}", f"{freq:.2f}%", f"{weight:.4f}"))
            
            # Generate chart
            self.generate_weights_chart(entity_info, region_info)
            
            messagebox.showinfo("Success", "Risk weights calculated successfully")
            
        except Exception as e:
            messagebox.showerror("Error", f"Weight calculation failed: {str(e)}")
    
    def generate_weights_chart(self, entity_info, region_info):
        """Generate risk weight distribution charts"""
        try:
            for widget in self.weights_chart_frame.winfo_children():
                widget.destroy()
            
            fig, axes = plt.subplots(1, 2, figsize=(14, 5))
            fig.suptitle('Statistical Risk Weight Distribution', fontsize=14, fontweight='bold')
            
            # Entity weights
            entities = list(entity_info['weights'].keys())
            weights = list(entity_info['weights'].values())
            axes[0].barh(entities, weights, color='steelblue')
            axes[0].set_title('Entity Risk Weights')
            axes[0].set_xlabel('Weight (0.1-1.0)')
            
            # Regional weights
            regions = list(region_info['weights'].keys())
            weights = list(region_info['weights'].values())
            axes[1].barh(regions, weights, color='darkgreen')
            axes[1].set_title('Regional Risk Weights')
            axes[1].set_xlabel('Weight (0.1-1.0)')
            
            plt.tight_layout()
            
            canvas = FigureCanvasTkAgg(fig, master=self.weights_chart_frame)
            canvas.draw()
            canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)
            
        except Exception as e:
            print(f"Weights chart error: {e}")
    
    def export_all(self):
        """Export all samples"""
        if not self.samples:
            messagebox.showerror("Error", "Generate samples first")
            return
        
        try:
            self.export_text.delete('1.0', tk.END)
            output = "EXPORT LOG\n" + "="*80 + "\n\n"
            
            for method, sample in self.samples.items():
                try:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"{self.engine.results_dir}/Sample_{method}_{timestamp}.csv"
                    sample.to_csv(filename, index=False)
                    
                    output += f"âœ… {method}: {filename}\n"
                except Exception as e:
                    output += f"âŒ {method}: {str(e)}\n"
            
            self.export_text.insert('1.0', output)
            messagebox.showinfo("Success", "Export completed!")
            
        except Exception as e:
            messagebox.showerror("Error", f"Export failed: {str(e)}")
    
    def export_risk_weights(self):
        """Export risk weights"""
        if self.data is None:
            messagebox.showerror("Error", "Load data first")
            return
        
        if not self.validate_config():
            return
        
        try:
            entity_col = self.strata_cols[0] if len(self.strata_cols) > 0 else None
            region_col = self.strata_cols[1] if len(self.strata_cols) > 1 else None
            
            if not entity_col or not region_col:
                messagebox.showerror("Error", "Need at least 2 stratification columns")
                return
            
            entity_info = self.engine.calculate_statistical_weights(self.data, entity_col)
            region_info = self.engine.calculate_statistical_weights(self.data, region_col)
            
            # Create export DataFrame
            export_data = []
            
            for entity, weight in entity_info['weights'].items():
                export_data.append({
                    'Category': 'Entity',
                    'Item': entity,
                    'Exception_Count': entity_info['counts'].get(entity, 0),
                    'Frequency_Percent': entity_info['frequencies'].get(entity, 0) * 100,
                    'Statistical_Weight': weight
                })
            
            for region, weight in region_info['weights'].items():
                export_data.append({
                    'Category': 'Region',
                    'Item': region,
                    'Exception_Count': region_info['counts'].get(region, 0),
                    'Frequency_Percent': region_info['frequencies'].get(region, 0) * 100,
                    'Statistical_Weight': weight
                })
            
            export_df = pd.DataFrame(export_data)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.engine.results_dir}/StatisticalRiskWeights_{timestamp}.csv"
            
            export_df.to_csv(filename, index=False)
            
            self.export_text.delete('1.0', tk.END)
            self.export_text.insert('1.0', f"âœ… Risk weights exported to:\n{filename}")
            
            messagebox.showinfo("Success", f"Risk weights exported to:\n{filename}")
            
        except Exception as e:
            messagebox.showerror("Error", f"Export failed: {str(e)}")
    
    def generate_audit_report(self):
        """Generate comprehensive audit report"""
        if not self.samples:
            messagebox.showerror("Error", "Generate samples first")
            return
        
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            report_content = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    AUDIT SAMPLING REPORT v6.5                                 â•‘
â•‘                  REGULATORY COMPLIANCE DOCUMENTATION                           â•‘
â•‘              With MUS & Statistical Risk Weighting Analysis                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Audit Period: {datetime.now().strftime('%Y-%m-%d')}

EXECUTIVE SUMMARY
{'='*80}

Sample Size: {sum(len(s) for s in self.samples.values()):,}
Population Size: {len(self.data):,}
Sampling Rate: {(sum(len(s) for s in self.samples.values()) / len(self.data) * 100):.2f}%

REGULATORY COMPLIANCE STANDARDS APPLIED
{'='*80}

âœ… AICPA AU-C Section 530 (Audit Sampling)
âœ… ISA 530 (International Standard on Auditing)
âœ… IIA Standards (Internal Audit Practice)
âœ… COSO Framework (Risk Assessment)
âœ… Monetary Unit Sampling (Value-Based)
âœ… Statistical Risk Weighting (Data-Driven)

SAMPLING METHODS APPLIED
{'='*80}

Methods Used: {', '.join(self.samples.keys())}

METHOD DETAILS:

1. Stratified Risk-Based Sampling
   - Risk weights calculated from exception frequency
   - Multi-factor risk analysis
   - Proportional sample allocation
   - Coverage optimization

2. Monetary Unit Sampling (MUS)
   - Value-based selection
   - Appropriate for high-value populations
   - Probability proportional to size
   - Efficient for material testing

3. Hybrid Enhanced Sampling
   - 50% Risk-based stratified
   - 30% Monetary Unit Sampling
   - 20% Anomaly detection
   - Comprehensive coverage

RISK ASSESSMENT SUMMARY
{'='*80}

Overall Risk Level: {self.risk_assessment.get('overall_risk', 'Not Assessed')}
Risk Score: {self.risk_assessment.get('risk_score', 'N/A')}

AUDIT PROCEDURES PERFORMED
{'='*80}

âœ… Population risk assessment completed
âœ… Statistical risk weighting calculated
âœ… Sample size determination per Cochran formula
âœ… Risk-based allocation performed
âœ… Monetary unit sampling executed
âœ… Anomaly detection analysis completed
âœ… Coverage analysis verified
âœ… Confidence intervals calculated
âœ… Results evaluated and documented
âœ… Audit trail maintained

CERTIFICATION
{'='*80}

This report certifies that the sampling plan was designed, executed, and evaluated
in accordance with professional auditing standards and regulatory requirements.

Prepared by: Audit Team
Date: {datetime.now().strftime('%Y-%m-%d')}

{'='*80}
END OF REPORT
{'='*80}
"""
            
            report_file = f"{self.engine.results_dir}/AuditReport_{timestamp}.txt"
            with open(report_file, 'w') as f:
                f.write(report_content)
            
            self.export_text.delete('1.0', tk.END)
            self.export_text.insert('1.0', f"âœ… Audit Report Generated:\n{report_file}")
            messagebox.showinfo("Success", f"Report saved to:\n{report_file}")
            
        except Exception as e:
            messagebox.showerror("Error", f"Report generation failed: {str(e)}")
    
    def export_summary(self):
        """Export summary statistics"""
        try:
            if not self.samples:
                messagebox.showerror("Error", "Generate samples first")
                return
            
            summary = "SAMPLING SUMMARY\n" + "="*80 + "\n\n"
            
            for method, sample in self.samples.items():
                summary += f"{method}:\n"
                summary += f"  Size: {len(sample):,}\n"
                
                numeric_cols = sample.select_dtypes(include=[np.number]).columns
                for col in numeric_cols[:3]:
                    summary += f"  {col} - Mean: {sample[col].mean():.2f}, Std: {sample[col].std():.2f}\n"
                
                summary += "\n"
            
            self.export_text.delete('1.0', tk.END)
            self.export_text.insert('1.0', summary)
            
        except Exception as e:
            messagebox.showerror("Error", f"Summary export failed: {str(e)}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    root = tk.Tk()
    app = ProfessionalAuditApp(root)
    root.mainloop()
