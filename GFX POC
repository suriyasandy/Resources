import streamlit as st
import pandas as pd
import numpy as np
import shap
import joblib
import matplotlib.pyplot as plt

# =========================================================
# PAGE CONFIG
# =========================================================
st.set_page_config(
    page_title="OMRC GFX Explainability Dashboard",
    layout="wide"
)

st.title("ðŸ“Š OMRC â€“ GFX Explainability & Prioritisation Dashboard")
st.caption(
    "Scope: FX Forwards & FX Swaps | "
    "Purpose: Execution-quality context, NOT trade linkage"
)

# =========================================================
# LOAD TRAINED ML MODEL
# =========================================================
@st.cache_resource
def load_model():
    return joblib.load("model.pkl")

model = load_model()

# =========================================================
# FILE UPLOAD
# =========================================================
file = st.file_uploader("Upload OMRC GFX Dataset (CSV)", type=["csv"])
if not file:
    st.warning("Please upload OMRC GFX data to continue.")
    st.stop()

df = pd.read_csv(file)

# =========================================================
# DATETIME HANDLING
# =========================================================
df["omrctradeTradedate"] = pd.to_datetime(df["omrctradeTradedate"])
df["trade_date"] = df["omrctradeTradedate"].dt.date

# =========================================================
# PRODUCT NORMALISATION
# =========================================================
PRODUCT_MAP = {
    "FXF": "FX Forward",
    "FXFO": "FX Forward",
    "FWD": "FX Forward",
    "FXS": "FX Swap",
    "SPOT": "FX Spot",
    "SPT": "FX Spot"
}

df["product_group"] = df["omrctradeProductsubtype"].map(PRODUCT_MAP)

# Phase-1 / Phase-2 scope
df = df[df["product_group"].isin(["FX Forward", "FX Swap"])]

# =========================================================
# TENOR BUCKETING (YOUR VALUES)
# =========================================================
TENOR_BUCKETS = {
    "ON": "Spot / Very Short", "TN": "Spot / Very Short",
    "SN": "Spot / Very Short", "SPT": "Spot / Very Short",
    "2W": "Short", "3W": "Short",
    "1M": "Short", "2M": "Short", "3M": "Short",
    "4M": "Medium", "5M": "Medium", "6M": "Medium",
    "7M": "Medium", "8M": "Medium", "9M": "Medium",
    "10M": "Medium", "11M": "Medium",
    "18M": "Long",
    "1Y": "Long", "2Y": "Long", "3Y": "Long", "4Y": "Long"
}

df["tenor_bucket"] = df["omrctradeTenor"].map(TENOR_BUCKETS).fillna("Other")

# =========================================================
# LIQUIDITY WINDOW
# =========================================================
def liquidity_window(ts):
    h = ts.hour
    if h < 6:
        return "Asia"
    elif h < 12:
        return "London"
    elif h < 17:
        return "NY"
    else:
        return "Off-hours"

df["liquidity_window"] = df["omrctradeTradedate"].apply(liquidity_window)

# =========================================================
# CURRENCY LIQUIDITY (G10 vs NON-G10)
# =========================================================
G10 = [
    "EUR/USD", "USD/JPY", "GBP/USD", "USD/CHF",
    "AUD/USD", "USD/CAD", "NZD/USD"
]

df["ccy_liquidity"] = df["omrctradeCcyPair"].apply(
    lambda x: "G10" if x in G10 else "Non-G10"
)

# =========================================================
# PRINCIPAL BUCKET
# =========================================================
df["principal_bucket"] = pd.cut(
    df["omrctradeBasecurrprincipalamt"],
    bins=[0, 25e6, 100e6, np.inf],
    labels=["Small", "Medium", "Large"]
)

# =========================================================
# PORTFOLIO CLUSTERING (BOOK + DAY + CCY)
# =========================================================
cluster_df = (
    df.groupby(["uctradeBookname", "trade_date", "omrctradeCcyPair"])
      .size()
      .reset_index(name="cluster_trade_count")
)

df = df.merge(
    cluster_df,
    on=["uctradeBookname", "trade_date", "omrctradeCcyPair"],
    how="left"
)

# =========================================================
# ML FEATURES
# =========================================================
FEATURES = [
    "product_group",
    "tenor_bucket",
    "liquidity_window",
    "principal_bucket",
    "ccy_liquidity",
    "cluster_trade_count"
]

# =========================================================
# ML SCORE (EXPLAINABILITY RANKING)
# =========================================================
df["ml_explainability_score"] = model.predict_proba(df[FEATURES])[:, 1]

df["review_priority"] = np.where(
    df["ml_explainability_score"] < 0.4,
    "High Priority",
    "Normal Priority"
)

# =========================================================
# SIDEBAR FILTERS
# =========================================================
st.sidebar.header("Filters")

ccy_filter = st.sidebar.multiselect(
    "Currency Pair",
    df["omrctradeCcyPair"].unique(),
    df["omrctradeCcyPair"].unique()
)

product_filter = st.sidebar.multiselect(
    "Product",
    df["product_group"].unique(),
    df["product_group"].unique()
)

book_filter = st.sidebar.multiselect(
    "Book",
    df["uctradeBookname"].dropna().unique(),
    df["uctradeBookname"].dropna().unique()
)

fdf = df[
    (df["omrctradeCcyPair"].isin(ccy_filter)) &
    (df["product_group"].isin(product_filter)) &
    (df["uctradeBookname"].isin(book_filter))
]

# =========================================================
# OVERVIEW TABLE
# =========================================================
st.subheader("ðŸ“‹ OMRC Alert Overview")

st.dataframe(
    fdf[
        [
            "exceptionId",
            "omrctradeCcyPair",
            "product_group",
            "omrctradeTenor",
            "principal_bucket",
            "liquidity_window",
            "cluster_trade_count",
            "ml_explainability_score",
            "review_priority"
        ]
    ].sort_values("ml_explainability_score"),
    use_container_width=True
)

# =========================================================
# PORTFOLIO ACTIVITY VISUAL
# =========================================================
st.subheader("ðŸ“ˆ Portfolio Activity (Same-Day Book Behaviour)")

portfolio_view = (
    fdf.groupby(["trade_date", "uctradeBookname"])
       .agg(trades=("exceptionId", "count"))
       .reset_index()
)

st.bar_chart(
    portfolio_view.set_index("trade_date")["trades"]
)

# =========================================================
# TRADE DRILLDOWN
# =========================================================
st.subheader("ðŸ” Trade Drilldown")

selected_id = st.selectbox(
    "Select Exception ID",
    fdf["exceptionId"].unique()
)

trade = fdf[fdf["exceptionId"] == selected_id].iloc[0]

st.json({
    "Currency Pair": trade["omrctradeCcyPair"],
    "Product": trade["product_group"],
    "Tenor": trade["omrctradeTenor"],
    "Principal Bucket": trade["principal_bucket"],
    "Liquidity Window": trade["liquidity_window"],
    "Same-Day Book Trades": int(trade["cluster_trade_count"]),
    "ML Explainability Score": round(trade["ml_explainability_score"], 3),
    "Review Priority": trade["review_priority"]
})

# =========================================================
# SHAP EXPLAINABILITY
# =========================================================
st.subheader("ðŸ§  ML Explainability (SHAP)")

X_row = trade[FEATURES].to_frame().T
X_transformed = model.named_steps["prep"].transform(X_row)

explainer = shap.Explainer(
    model.named_steps["clf"],
    model.named_steps["prep"].transform(df[FEATURES])
)

shap_values = explainer(X_transformed)

fig, ax = plt.subplots()
shap.plots.bar(shap_values[0], max_display=10, show=False)
st.pyplot(fig)

# =========================================================
# AUTO-DRAFT OMRC EXPLANATION
# =========================================================
st.subheader("ðŸ“ OMRC Explanation (Auto-Draft)")

st.info(
    f"""
    The {trade['product_group']} trade in {trade['omrctradeCcyPair']} with tenor
    {trade['omrctradeTenor']} was executed during the {trade['liquidity_window']} window.
    The trade formed part of {int(trade['cluster_trade_count'])} same-day trades in the same
    book and currency. Based on trade size, execution timing, tenor profile, and portfolio
    activity, the execution context appears economically explainable.
    The ML score is used solely for review prioritisation and does not represent a determination
    of misconduct or intent.
    """
)
