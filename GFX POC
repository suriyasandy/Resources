import streamlit as st
import pandas as pd
import numpy as np

# =========================================================
# PAGE CONFIG
# =========================================================
st.set_page_config(
    page_title="OMRC GFX ‚Äì Execution Context Viewer",
    layout="wide"
)

st.title("üìä OMRC ‚Äì GFX Execution Context Viewer")
st.caption(
    "Purpose: Surface execution context only | "
    "No pricing judgement | No linkage | No auto-closure"
)

# =========================================================
# FILE UPLOAD
# =========================================================
file = st.file_uploader("Upload OMRC GFX Dataset (CSV)", type=["csv"])
if not file:
    st.warning("Please upload OMRC GFX data to continue.")
    st.stop()

df = pd.read_csv(file)

# =========================================================
# DATETIME HANDLING
# =========================================================
df["omrctradeTradedate"] = pd.to_datetime(
    df["omrctradeTradedate"], errors="coerce"
)
df["trade_date"] = df["omrctradeTradedate"].dt.date

# =========================================================
# PRODUCT NORMALISATION
# =========================================================
PRODUCT_MAP = {
    "FXF": "FX Forward",
    "FXFO": "FX Forward",
    "FWD": "FX Forward",
    "FXS": "FX Swap",
    "SPOT": "FX Spot",
    "SPT": "FX Spot"
}

df["product_group"] = df["omrctradeProductsubtype"].map(PRODUCT_MAP)

df = df[df["product_group"].isin(["FX Forward", "FX Swap"])]

# =========================================================
# TENOR BUCKETING
# =========================================================
TENOR_BUCKETS = {
    "ON": "Very Short", "TN": "Very Short", "SN": "Very Short", "SPT": "Very Short",
    "2W": "Short", "3W": "Short",
    "1M": "Short", "2M": "Short", "3M": "Short",
    "4M": "Medium", "5M": "Medium", "6M": "Medium",
    "7M": "Medium", "8M": "Medium", "9M": "Medium",
    "10M": "Medium", "11M": "Medium",
    "18M": "Long",
    "1Y": "Long", "2Y": "Long", "3Y": "Long", "4Y": "Long"
}

df["tenor_bucket"] = df["omrctradeTenor"].map(TENOR_BUCKETS)

# =========================================================
# LIQUIDITY WINDOW
# =========================================================
def liquidity_window(ts):
    if pd.isna(ts):
        return np.nan
    h = ts.hour
    if h < 6:
        return "Asia"
    elif h < 12:
        return "London"
    elif h < 17:
        return "New York"
    else:
        return "Off-hours"

df["liquidity_window"] = df["omrctradeTradedate"].apply(liquidity_window)

# =========================================================
# PRINCIPAL BUCKET
# =========================================================
df["principal_bucket"] = pd.cut(
    df["omrctradeBasecurrprincipalamt"],
    bins=[0, 25e6, 100e6, np.inf],
    labels=["Small", "Medium", "Large"]
)

# =========================================================
# CURRENCY LIQUIDITY (STRUCTURAL)
# =========================================================
G10 = [
    "EUR/USD", "USD/JPY", "GBP/USD", "USD/CHF",
    "AUD/USD", "USD/CAD", "NZD/USD"
]

df["ccy_liquidity"] = df["omrctradeCcyPair"].apply(
    lambda x: "G10" if x in G10 else "Non-G10"
)

# =========================================================
# PORTFOLIO CLUSTERING (BOOK + DAY + CCY)
# =========================================================
cluster_df = (
    df.groupby(["uctradeBookname", "trade_date", "omrctradeCcyPair"])
      .size()
      .reset_index(name="cluster_trade_count")
)

df = df.merge(
    cluster_df,
    on=["uctradeBookname", "trade_date", "omrctradeCcyPair"],
    how="left"
)

# =========================================================
# BTB / LIFECYCLE FLAGS
# =========================================================
# Assumption (as per your note):
# omrctradebuivalue identifies BTB trades
df["btb_flag"] = df["omrctradebuivalue"].astype(str).str.upper().isin(
    ["BTB", "BACKTOBACK", "BACK_TO_BACK"]
)

# Optional lifecycle flags (only if present)
df["amended_flag"] = df.get("amendedFlag", False)
df["cancelled_flag"] = df.get("cancelledFlag", False)

# =========================================================
# STRICT ALLOWED LANGUAGE EXPLANATION BUILDER
# =========================================================
def build_explanation(row):
    explanation = []

    # ---------- FACTUAL ----------
    if pd.notna(row["liquidity_window"]):
        explanation.append(
            f"Trade executed during {row['liquidity_window']} hours."
        )

    if pd.notna(row["principal_bucket"]):
        explanation.append(
            f"Trade size is categorised as {row['principal_bucket']}."
        )

    if pd.notna(row["tenor_bucket"]):
        explanation.append(
            f"Trade tenor falls into the {row['tenor_bucket']} bucket."
        )

    if pd.notna(row["ccy_liquidity"]):
        explanation.append(
            f"Currency pair is classified as {row['ccy_liquidity']}."
        )

    # ---------- CONTEXTUAL (NON-JUDGEMENTAL) ----------
    context_drivers = 0

    if row["liquidity_window"] in ["Asia", "Off-hours"]:
        explanation.append(
            "Execution occurred during a lower-liquidity market window."
        )
        context_drivers += 1

    if row["tenor_bucket"] in ["Medium", "Long"]:
        explanation.append(
            "Tenor profile increases sensitivity to forward pricing assumptions."
        )
        context_drivers += 1

    if row["cluster_trade_count"] >= 2:
        explanation.append(
            "Multiple trades observed in the same book and currency on the same day."
        )
        context_drivers += 1

    # ---------- LIFECYCLE ----------
    if row["btb_flag"]:
        explanation.append(
            "Trade identified as back-to-back execution; internal transfer characteristics may apply."
        )

    if row["amended_flag"]:
        explanation.append(
            "Trade has been amended post initial execution; amendment timing may influence observed values."
        )

    if row["cancelled_flag"]:
        explanation.append(
            "Trade marked as cancelled; alert retained for audit traceability."
        )

    # ---------- RULE CONTEXT ----------
    rule_reason = row.get("rule_failure_reason")
    if pd.notna(rule_reason) and str(rule_reason).strip() != "":
        explanation.append(
            f"Rule failure reason recorded as: {rule_reason}"
        )
    else:
        explanation.append(
            "No explicit rule failure reason recorded for this alert."
        )

    # ---------- OUTCOME (STRICT) ----------
    if context_drivers >= 2:
        explanation.append(
            "Multiple execution context factors are present that may explain the alert trigger."
        )
    else:
        explanation.append(
            "Limited execution context factors observed; further review may be required."
        )

    return explanation

# =========================================================
# FILTERS
# =========================================================
st.sidebar.header("Filters")

ccy_filter = st.sidebar.multiselect(
    "Currency Pair",
    df["omrctradeCcyPair"].unique(),
    df["omrctradeCcyPair"].unique()
)

book_filter = st.sidebar.multiselect(
    "Book",
    df["uctradeBookname"].dropna().unique(),
    df["uctradeBookname"].dropna().unique()
)

fdf = df[
    (df["omrctradeCcyPair"].isin(ccy_filter)) &
    (df["uctradeBookname"].isin(book_filter))
]

# =========================================================
# OVERVIEW TABLE
# =========================================================
st.subheader("üìã OMRC Alert Overview")

st.dataframe(
    fdf[
        [
            "exceptionId",
            "omrctradeCcyPair",
            "product_group",
            "omrctradeTenor",
            "principal_bucket",
            "liquidity_window",
            "cluster_trade_count",
            "btb_flag"
        ]
    ],
    use_container_width=True
)

# =========================================================
# DRILLDOWN
# =========================================================
st.subheader("üîç Trade Drilldown")

selected_id = st.selectbox(
    "Select Exception ID",
    fdf["exceptionId"].unique()
)

trade = fdf[fdf["exceptionId"] == selected_id].iloc[0]

st.json({
    "Currency Pair": trade["omrctradeCcyPair"],
    "Product": trade["product_group"],
    "Tenor": trade["omrctradeTenor"],
    "Principal Bucket": trade["principal_bucket"],
    "Liquidity Window": trade["liquidity_window"],
    "BTB Trade": trade["btb_flag"],
    "Same-Day Book Trades": int(trade["cluster_trade_count"])
})

# =========================================================
# EXECUTION CONTEXT SUMMARY
# =========================================================
st.subheader("üìù Execution Context Summary (OMRC-Safe)")

for line in build_explanation(trade):
    st.write("‚Ä¢", line)
