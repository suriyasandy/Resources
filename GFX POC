import streamlit as st
import polars as pl
from pathlib import Path

# ----------------------------------------------------
# PAGE CONFIG
# ----------------------------------------------------
st.set_page_config(page_title="OMRC – GFX Execution Context", layout="wide")

st.title("OMRC – GFX Execution Context Platform")
st.caption("Historical baseline | Latest trade inference | OMRC-safe explanations")

# ----------------------------------------------------
# CONFIG
# ----------------------------------------------------
DATA_DIR = Path("./data")
DATA_DIR.mkdir(exist_ok=True)

HIST_PARQUET = DATA_DIR / "historical_gfx.parquet"

DATE_FORMAT = "%d/%m/%Y %H:%M:%S%.f"

REQUIRED_COLS = [
    "book",
    "ccy_pair",
    "tenor",
    "trade_date",
    "base_currency_prin_amount",
    "bui_value"
]

# ----------------------------------------------------
# HELPERS
# ----------------------------------------------------
def ensure_columns(df):
    for c in REQUIRED_COLS:
        if c not in df.columns:
            df = df.with_columns(pl.lit(None).alias(c))
    return df

def parse_trade_date(df):
    return df.with_columns(
        pl.col("trade_date")
        .cast(pl.Utf8, strict=False)
        .str.strptime(pl.Datetime, DATE_FORMAT, strict=False)
        .alias("trade_datetime")
    ).with_columns(
        pl.col("trade_datetime").dt.date().alias("trade_date_only")
    )

def load_any(file):
    if file.name.endswith(".parquet"):
        return pl.read_parquet(file)
    return pl.read_csv(file, ignore_errors=True)

def build_baseline(df):
    has_dates = df.select(pl.col("trade_date_only").drop_nulls().count()).item() > 0

    if has_dates:
        keys = ["book", "trade_date_only", "ccy_pair"]
        note = "Baseline uses trade date"
    else:
        keys = ["book", "ccy_pair", "tenor"]
        note = "Baseline uses structural grouping (no valid trade dates)"

    baseline = (
        df.group_by(keys)
        .agg([
            pl.median("base_currency_prin_amount").alias("baseline_median_principal"),
            pl.count().alias("baseline_trade_count")
        ])
    )
    return baseline, keys, note

def generate_explanation(row):
    msgs = []

    if row["is_btb"]:
        msgs.append("Back-to-back trade")

    if row["principal_ratio"] > 3:
        msgs.append("Execution notional materially larger than historical median")

    if row["baseline_trade_count"] < 5:
        msgs.append("Limited historical reference for this execution")

    if not msgs:
        msgs.append("Execution consistent with historical trading behaviour")

    return "; ".join(msgs)

# ----------------------------------------------------
# SECTION 1 – HISTORICAL BASELINE
# ----------------------------------------------------
st.header("1️⃣ Historical Baseline Setup (One-time)")

hist_path = st.text_input(
    "Provide path to historical GFX CSV (will be converted to Parquet)",
    placeholder="C:/data/GFX_HIST_20260101_20260107.csv"
)

if st.button("Prepare Historical Baseline"):
    if not hist_path:
        st.error("Please provide a valid file path")
    else:
        with st.spinner("Loading historical data..."):
            hist_df = pl.read_csv(hist_path, ignore_errors=True)
            hist_df = ensure_columns(hist_df)
            hist_df = parse_trade_date(hist_df)
            hist_df.write_parquet(HIST_PARQUET)

        st.success(f"Historical baseline saved to {HIST_PARQUET}")

# ----------------------------------------------------
# STOP if no baseline exists
# ----------------------------------------------------
if not HIST_PARQUET.exists():
    st.warning("Please prepare historical baseline before uploading latest file")
    st.stop()

# ----------------------------------------------------
# SECTION 2 – LATEST FILE INFERENCE
# ----------------------------------------------------
st.header("2️⃣ Upload Latest GFX Trade File (Daily)")

latest_file = st.file_uploader(
    "Upload latest GFX CSV or Parquet",
    type=["csv", "parquet"]
)

if not latest_file:
    st.stop()

with st.spinner("Loading latest trades..."):
    latest_df = load_any(latest_file)
    latest_df = ensure_columns(latest_df)
    latest_df = parse_trade_date(latest_df)

st.success(f"Loaded {latest_df.height:,} latest trades")

# ----------------------------------------------------
# LOAD BASELINE
# ----------------------------------------------------
hist_df = pl.read_parquet(HIST_PARQUET)

baseline_df, baseline_keys, baseline_note = build_baseline(hist_df)

st.info(baseline_note)

# ----------------------------------------------------
# JOIN BASELINE TO LATEST
# ----------------------------------------------------
latest_df = latest_df.join(baseline_df, on=baseline_keys, how="left")

# ----------------------------------------------------
# FEATURES
# ----------------------------------------------------
latest_df = latest_df.with_columns([
    (pl.col("base_currency_prin_amount") /
     pl.col("baseline_median_principal")).alias("principal_ratio"),

    (pl.col("bui_value") == "BTB").fill_null(False).alias("is_btb")
])

# ----------------------------------------------------
# EXPLANATIONS
# ----------------------------------------------------
latest_df = latest_df.with_columns(
    pl.struct([
        "principal_ratio",
        "baseline_trade_count",
        "is_btb"
    ]).map_elements(generate_explanation).alias("execution_explanation")
)

# ----------------------------------------------------
# DISPLAY
# ----------------------------------------------------
st.header("3️⃣ Execution Context Output")

cols = [
    "book",
    "ccy_pair",
    "tenor",
    "base_currency_prin_amount",
    "baseline_median_principal",
    "baseline_trade_count",
    "execution_explanation"
]

st.dataframe(
    latest_df.select([c for c in cols if c in latest_df.columns]).head(500),
    use_container_width=True
)

# ----------------------------------------------------
# SUMMARY METRICS
# ----------------------------------------------------
st.header("4️⃣ Summary")

st.metric(
    "Elevated Notional Trades",
    latest_df.filter(pl.col("principal_ratio") > 3).height
)

st.metric(
    "Back-to-Back Trades",
    latest_df.filter(pl.col("is_btb")).height
)

st.metric(
    "Low Baseline Confidence",
    latest_df.filter(pl.col("baseline_trade_count") < 5).height
)

st.success("Inference completed successfully")
